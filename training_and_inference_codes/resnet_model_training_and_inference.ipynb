{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T08:32:59.125465Z",
     "iopub.status.busy": "2024-11-16T08:32:59.124837Z",
     "iopub.status.idle": "2024-11-16T08:32:59.133881Z",
     "shell.execute_reply": "2024-11-16T08:32:59.132760Z",
     "shell.execute_reply.started": "2024-11-16T08:32:59.125414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import ViTModel, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T08:33:03.527155Z",
     "iopub.status.busy": "2024-11-16T08:33:03.526763Z",
     "iopub.status.idle": "2024-11-16T08:33:03.532169Z",
     "shell.execute_reply": "2024-11-16T08:33:03.531038Z",
     "shell.execute_reply.started": "2024-11-16T08:33:03.527122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_csv_path = '/kaggle/input/visual-taxonomy/train.csv'\n",
    "test_csv_path = '/kaggle/input/visual-taxonomy/test.csv'\n",
    "category_attributes_path = '/kaggle/input/visual-taxonomy/category_attributes.parquet'\n",
    "sample_submission_path = '/kaggle/input/visual-taxonomy/sample_submission.csv'\n",
    "images_folder = '/kaggle/input/visual-taxonomy/train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T08:33:03.948236Z",
     "iopub.status.busy": "2024-11-16T08:33:03.947857Z",
     "iopub.status.idle": "2024-11-16T08:33:04.210733Z",
     "shell.execute_reply": "2024-11-16T08:33:04.209689Z",
     "shell.execute_reply.started": "2024-11-16T08:33:03.948198Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train.csv ...\n",
      "train.csv shape: (70213, 13)\n",
      "train.csv columns: Index(['id', 'Category', 'len', 'attr_1', 'attr_2', 'attr_3', 'attr_4',\n",
      "       'attr_5', 'attr_6', 'attr_7', 'attr_8', 'attr_9', 'attr_10'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>default</td>\n",
       "      <td>round</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>default</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Category  len      attr_1 attr_2   attr_3   attr_4         attr_5  \\\n",
       "0   0  Men Tshirts    5     default  round  printed  default  short sleeves   \n",
       "1   1  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
       "2   2  Men Tshirts    5     default   polo    solid    solid  short sleeves   \n",
       "3   3  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
       "4   4  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
       "\n",
       "  attr_6 attr_7 attr_8 attr_9 attr_10  \n",
       "0    NaN    NaN    NaN    NaN     NaN  \n",
       "1    NaN    NaN    NaN    NaN     NaN  \n",
       "2    NaN    NaN    NaN    NaN     NaN  \n",
       "3    NaN    NaN    NaN    NaN     NaN  \n",
       "4    NaN    NaN    NaN    NaN     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nLoading train.csv ...\")\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "print(f\"train.csv shape: {train_df.shape}\")\n",
    "print(f\"train.csv columns: {train_df.columns}\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T08:33:04.347591Z",
     "iopub.status.busy": "2024-11-16T08:33:04.347137Z",
     "iopub.status.idle": "2024-11-16T08:33:04.381366Z",
     "shell.execute_reply": "2024-11-16T08:33:04.380378Z",
     "shell.execute_reply.started": "2024-11-16T08:33:04.347547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading test.csv ...\n",
      "test.csv shape: (30205, 2)\n",
      "test.csv columns: Index(['id', 'Category'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Category\n",
       "0   0  Men Tshirts\n",
       "1   1  Men Tshirts\n",
       "2   2  Men Tshirts\n",
       "3   3  Men Tshirts\n",
       "4   4  Men Tshirts"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nLoading test.csv ...\")\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "print(f\"test.csv shape: {test_df.shape}\")\n",
    "print(f\"test.csv columns: {test_df.columns}\")\n",
    "\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:50:26.656594Z",
     "iopub.status.busy": "2024-11-16T10:50:26.655728Z",
     "iopub.status.idle": "2024-11-16T10:50:26.857540Z",
     "shell.execute_reply": "2024-11-16T10:50:26.856573Z",
     "shell.execute_reply.started": "2024-11-16T10:50:26.656549Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7267 entries, 0 to 7266\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7267 non-null   int64 \n",
      " 1   Category  7267 non-null   object\n",
      " 2   len       7267 non-null   int64 \n",
      " 3   attr_1    6010 non-null   object\n",
      " 4   attr_2    6144 non-null   object\n",
      " 5   attr_3    5791 non-null   object\n",
      " 6   attr_4    5949 non-null   object\n",
      " 7   attr_5    5977 non-null   object\n",
      " 8   attr_6    0 non-null      object\n",
      " 9   attr_7    0 non-null      object\n",
      " 10  attr_8    0 non-null      object\n",
      " 11  attr_9    0 non-null      object\n",
      " 12  attr_10   0 non-null      object\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 794.8+ KB\n",
      "Men Tshirts DataFrame:\n",
      "None\n",
      "   id     Category  len      attr_1 attr_2   attr_3   attr_4         attr_5  \\\n",
      "0   0  Men Tshirts    5     default  round  printed  default  short sleeves   \n",
      "1   1  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
      "2   2  Men Tshirts    5     default   polo    solid    solid  short sleeves   \n",
      "3   3  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
      "4   4  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
      "\n",
      "  attr_6 attr_7 attr_8 attr_9 attr_10  \n",
      "0    NaN    NaN    NaN    NaN     NaN  \n",
      "1    NaN    NaN    NaN    NaN     NaN  \n",
      "2    NaN    NaN    NaN    NaN     NaN  \n",
      "3    NaN    NaN    NaN    NaN     NaN  \n",
      "4    NaN    NaN    NaN    NaN     NaN  \n",
      "7267\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18346 entries, 7267 to 25612\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        18346 non-null  int64 \n",
      " 1   Category  18346 non-null  object\n",
      " 2   len       18346 non-null  int64 \n",
      " 3   attr_1    7885 non-null   object\n",
      " 4   attr_2    17679 non-null  object\n",
      " 5   attr_3    15861 non-null  object\n",
      " 6   attr_4    17896 non-null  object\n",
      " 7   attr_5    17649 non-null  object\n",
      " 8   attr_6    5010 non-null   object\n",
      " 9   attr_7    8896 non-null   object\n",
      " 10  attr_8    16465 non-null  object\n",
      " 11  attr_9    14303 non-null  object\n",
      " 12  attr_10   17818 non-null  object\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 2.0+ MB\n",
      "Sarees DataFrame:\n",
      "None\n",
      "        id Category  len         attr_1        attr_2        attr_3  \\\n",
      "7267  7432   Sarees   10  same as saree  woven design  small border   \n",
      "7268  7433   Sarees   10            NaN          zari  small border   \n",
      "7269  7434   Sarees   10            NaN          zari  small border   \n",
      "7270  7435   Sarees   10  same as saree  woven design    big border   \n",
      "7271  7436   Sarees   10          solid     no border           NaN   \n",
      "\n",
      "          attr_4       attr_5    attr_6         attr_7      attr_8  \\\n",
      "7267  multicolor        party  jacquard   woven design  zari woven   \n",
      "7268       cream  traditional       NaN            NaN  zari woven   \n",
      "7269       white        party       NaN            NaN  zari woven   \n",
      "7270     default  traditional       NaN  same as saree  zari woven   \n",
      "7271         NaN        daily       NaN            NaN         NaN   \n",
      "\n",
      "            attr_9 attr_10  \n",
      "7267      applique      no  \n",
      "7268      elephant      no  \n",
      "7269        floral      no  \n",
      "7270  ethnic motif      no  \n",
      "7271           NaN     yes  \n",
      "18346\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6822 entries, 25613 to 32434\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        6822 non-null   int64 \n",
      " 1   Category  6822 non-null   object\n",
      " 2   len       6822 non-null   int64 \n",
      " 3   attr_1    6629 non-null   object\n",
      " 4   attr_2    3231 non-null   object\n",
      " 5   attr_3    3400 non-null   object\n",
      " 6   attr_4    6431 non-null   object\n",
      " 7   attr_5    3266 non-null   object\n",
      " 8   attr_6    3848 non-null   object\n",
      " 9   attr_7    3843 non-null   object\n",
      " 10  attr_8    6702 non-null   object\n",
      " 11  attr_9    6691 non-null   object\n",
      " 12  attr_10   0 non-null      object\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 746.2+ KB\n",
      "Kurtis DataFrame:\n",
      "None\n",
      "          id Category  len     attr_1    attr_2       attr_3 attr_4   attr_5  \\\n",
      "25613  25778   Kurtis    9      black  straight  knee length  daily      net   \n",
      "25614  25779   Kurtis    9        red  straight  knee length  daily  default   \n",
      "25615  25780   Kurtis    9        red  straight  knee length  daily  default   \n",
      "25616  25781   Kurtis    9  navy blue  straight  knee length  daily  default   \n",
      "25617  25782   Kurtis    9      black  straight  knee length  daily  default   \n",
      "\n",
      "        attr_6   attr_7                 attr_8   attr_9 attr_10  \n",
      "25613    solid    solid  three-quarter sleeves  regular     NaN  \n",
      "25614  default  default  three-quarter sleeves  regular     NaN  \n",
      "25615  default  default  three-quarter sleeves  regular     NaN  \n",
      "25616  default  default  three-quarter sleeves  regular     NaN  \n",
      "25617  default  default  three-quarter sleeves  regular     NaN  \n",
      "6822\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18774 entries, 32435 to 51208\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        18774 non-null  int64 \n",
      " 1   Category  18774 non-null  object\n",
      " 2   len       18774 non-null  int64 \n",
      " 3   attr_1    17285 non-null  object\n",
      " 4   attr_2    14801 non-null  object\n",
      " 5   attr_3    16580 non-null  object\n",
      " 6   attr_4    16161 non-null  object\n",
      " 7   attr_5    17034 non-null  object\n",
      " 8   attr_6    16041 non-null  object\n",
      " 9   attr_7    15460 non-null  object\n",
      " 10  attr_8    510 non-null    object\n",
      " 11  attr_9    0 non-null      object\n",
      " 12  attr_10   0 non-null      object\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 2.0+ MB\n",
      "Women Tshirts:\n",
      "None\n",
      "          id       Category  len      attr_1 attr_2 attr_3   attr_4   attr_5  \\\n",
      "32435  32601  Women Tshirts    8  multicolor  loose   long  default  default   \n",
      "32436  32602  Women Tshirts    8      yellow  loose   long  default  default   \n",
      "32437  32603  Women Tshirts    8  multicolor  loose   long  default  default   \n",
      "32438  32604  Women Tshirts    8  multicolor  loose   long  default  default   \n",
      "32439  32605  Women Tshirts    8  multicolor  loose   long  default  default   \n",
      "\n",
      "             attr_6           attr_7 attr_8 attr_9 attr_10  \n",
      "32435       default  regular sleeves    NaN    NaN     NaN  \n",
      "32436  long sleeves  regular sleeves    NaN    NaN     NaN  \n",
      "32437       default  regular sleeves    NaN    NaN     NaN  \n",
      "32438  long sleeves  regular sleeves    NaN    NaN     NaN  \n",
      "32439       default  regular sleeves    NaN    NaN     NaN  \n",
      "18774\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19004 entries, 51209 to 70212\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        19004 non-null  int64 \n",
      " 1   Category  19004 non-null  object\n",
      " 2   len       19004 non-null  int64 \n",
      " 3   attr_1    14058 non-null  object\n",
      " 4   attr_2    13337 non-null  object\n",
      " 5   attr_3    13066 non-null  object\n",
      " 6   attr_4    13451 non-null  object\n",
      " 7   attr_5    12567 non-null  object\n",
      " 8   attr_6    13217 non-null  object\n",
      " 9   attr_7    13216 non-null  object\n",
      " 10  attr_8    13797 non-null  object\n",
      " 11  attr_9    12571 non-null  object\n",
      " 12  attr_10   7181 non-null   object\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 2.0+ MB\n",
      "Women Tops and Tunics DataFrame:\n",
      "None\n",
      "          id       Category  len      attr_1 attr_2 attr_3   attr_4   attr_5  \\\n",
      "32435  32601  Women Tshirts    8  multicolor  loose   long  default  default   \n",
      "32436  32602  Women Tshirts    8      yellow  loose   long  default  default   \n",
      "32437  32603  Women Tshirts    8  multicolor  loose   long  default  default   \n",
      "32438  32604  Women Tshirts    8  multicolor  loose   long  default  default   \n",
      "32439  32605  Women Tshirts    8  multicolor  loose   long  default  default   \n",
      "\n",
      "             attr_6           attr_7 attr_8 attr_9 attr_10  \n",
      "32435       default  regular sleeves    NaN    NaN     NaN  \n",
      "32436  long sleeves  regular sleeves    NaN    NaN     NaN  \n",
      "32437       default  regular sleeves    NaN    NaN     NaN  \n",
      "32438  long sleeves  regular sleeves    NaN    NaN     NaN  \n",
      "32439       default  regular sleeves    NaN    NaN     NaN  \n",
      "18774\n"
     ]
    }
   ],
   "source": [
    "category_dfs = {}\n",
    "\n",
    "for category in train_df['Category'].unique():\n",
    "    category_dfs[category] = train_df[train_df['Category'] == category]\n",
    "\n",
    "men_tshirts_df = category_dfs['Men Tshirts']\n",
    "print(f\"Men Tshirts DataFrame:\\n{men_tshirts_df.info()}\")\n",
    "print(men_tshirts_df.head())\n",
    "print(len(men_tshirts_df))\n",
    "\n",
    "sarees_df = category_dfs['Sarees']\n",
    "print(f\"Sarees DataFrame:\\n{sarees_df.info()}\")\n",
    "print(sarees_df.head())\n",
    "print(len(sarees_df))\n",
    "\n",
    "kurtis_df = category_dfs['Kurtis']\n",
    "print(f\"Kurtis DataFrame:\\n{kurtis_df.info()}\")\n",
    "print(kurtis_df.head())\n",
    "print(len(kurtis_df))\n",
    "\n",
    "women_tshirts_df = category_dfs['Women Tshirts']\n",
    "print(f\"Women Tshirts:\\n{women_tshirts_df.info()}\")\n",
    "print(women_tshirts_df.head())\n",
    "print(len(women_tshirts_df))\n",
    "\n",
    "women_tops_df = category_dfs['Women Tops & Tunics']\n",
    "print(f\"Women Tops and Tunics DataFrame:\\n{women_tops_df.info()}\")\n",
    "print(women_tshirts_df.head())\n",
    "print(len(women_tshirts_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T08:33:25.142167Z",
     "iopub.status.busy": "2024-11-16T08:33:25.141023Z",
     "iopub.status.idle": "2024-11-16T08:33:25.148174Z",
     "shell.execute_reply": "2024-11-16T08:33:25.147189Z",
     "shell.execute_reply.started": "2024-11-16T08:33:25.142115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing function for images\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.keras.applications.resnet.preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:50:35.199239Z",
     "iopub.status.busy": "2024-11-16T10:50:35.198546Z",
     "iopub.status.idle": "2024-11-16T11:10:34.662378Z",
     "shell.execute_reply": "2024-11-16T11:10:34.661194Z",
     "shell.execute_reply.started": "2024-11-16T10:50:35.199194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_30/1591116858.py:141: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Training Epoch 1/10:   0%|          | 0/402 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_30/1591116858.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training Epoch 1/10: 100%|██████████| 402/402 [01:47<00:00,  4.62it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy for attr_1: 0.8626\n",
      "Epoch 1, Validation Accuracy for attr_2: 0.6799\n",
      "Epoch 1, Validation Accuracy for attr_3: 0.8285\n",
      "Epoch 1, Validation Accuracy for attr_4: 0.5469\n",
      "Epoch 1, Validation Accuracy for attr_5: 0.6784\n",
      "Epoch 1, Validation Accuracy for attr_6: 0.9560\n",
      "Epoch 1, Validation Accuracy for attr_7: 0.7122\n",
      "Epoch 1, Validation Accuracy for attr_8: 0.8532\n",
      "Epoch 1, Validation Accuracy for attr_9: 0.6363\n",
      "Epoch 1, Validation Accuracy for attr_10: 0.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy for attr_1: 0.8601\n",
      "Epoch 2, Validation Accuracy for attr_2: 0.6621\n",
      "Epoch 2, Validation Accuracy for attr_3: 0.8474\n",
      "Epoch 2, Validation Accuracy for attr_4: 0.5458\n",
      "Epoch 2, Validation Accuracy for attr_5: 0.6966\n",
      "Epoch 2, Validation Accuracy for attr_6: 0.9560\n",
      "Epoch 2, Validation Accuracy for attr_7: 0.7242\n",
      "Epoch 2, Validation Accuracy for attr_8: 0.8488\n",
      "Epoch 2, Validation Accuracy for attr_9: 0.6461\n",
      "Epoch 2, Validation Accuracy for attr_10: 0.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy for attr_1: 0.8601\n",
      "Epoch 3, Validation Accuracy for attr_2: 0.6791\n",
      "Epoch 3, Validation Accuracy for attr_3: 0.8310\n",
      "Epoch 3, Validation Accuracy for attr_4: 0.5505\n",
      "Epoch 3, Validation Accuracy for attr_5: 0.7053\n",
      "Epoch 3, Validation Accuracy for attr_6: 0.9557\n",
      "Epoch 3, Validation Accuracy for attr_7: 0.7158\n",
      "Epoch 3, Validation Accuracy for attr_8: 0.8539\n",
      "Epoch 3, Validation Accuracy for attr_9: 0.6530\n",
      "Epoch 3, Validation Accuracy for attr_10: 0.8361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy for attr_1: 0.8619\n",
      "Epoch 4, Validation Accuracy for attr_2: 0.6879\n",
      "Epoch 4, Validation Accuracy for attr_3: 0.8496\n",
      "Epoch 4, Validation Accuracy for attr_4: 0.5483\n",
      "Epoch 4, Validation Accuracy for attr_5: 0.7151\n",
      "Epoch 4, Validation Accuracy for attr_6: 0.9564\n",
      "Epoch 4, Validation Accuracy for attr_7: 0.7329\n",
      "Epoch 4, Validation Accuracy for attr_8: 0.8666\n",
      "Epoch 4, Validation Accuracy for attr_9: 0.6512\n",
      "Epoch 4, Validation Accuracy for attr_10: 0.8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy for attr_1: 0.8630\n",
      "Epoch 5, Validation Accuracy for attr_2: 0.6908\n",
      "Epoch 5, Validation Accuracy for attr_3: 0.8419\n",
      "Epoch 5, Validation Accuracy for attr_4: 0.5643\n",
      "Epoch 5, Validation Accuracy for attr_5: 0.7144\n",
      "Epoch 5, Validation Accuracy for attr_6: 0.9608\n",
      "Epoch 5, Validation Accuracy for attr_7: 0.7355\n",
      "Epoch 5, Validation Accuracy for attr_8: 0.8681\n",
      "Epoch 5, Validation Accuracy for attr_9: 0.6570\n",
      "Epoch 5, Validation Accuracy for attr_10: 0.8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy for attr_1: 0.8637\n",
      "Epoch 6, Validation Accuracy for attr_2: 0.6868\n",
      "Epoch 6, Validation Accuracy for attr_3: 0.8488\n",
      "Epoch 6, Validation Accuracy for attr_4: 0.5723\n",
      "Epoch 6, Validation Accuracy for attr_5: 0.7104\n",
      "Epoch 6, Validation Accuracy for attr_6: 0.9517\n",
      "Epoch 6, Validation Accuracy for attr_7: 0.7398\n",
      "Epoch 6, Validation Accuracy for attr_8: 0.8659\n",
      "Epoch 6, Validation Accuracy for attr_9: 0.6446\n",
      "Epoch 6, Validation Accuracy for attr_10: 0.8358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy for attr_1: 0.8659\n",
      "Epoch 7, Validation Accuracy for attr_2: 0.6962\n",
      "Epoch 7, Validation Accuracy for attr_3: 0.8528\n",
      "Epoch 7, Validation Accuracy for attr_4: 0.5705\n",
      "Epoch 7, Validation Accuracy for attr_5: 0.7144\n",
      "Epoch 7, Validation Accuracy for attr_6: 0.9578\n",
      "Epoch 7, Validation Accuracy for attr_7: 0.7366\n",
      "Epoch 7, Validation Accuracy for attr_8: 0.8695\n",
      "Epoch 7, Validation Accuracy for attr_9: 0.6584\n",
      "Epoch 7, Validation Accuracy for attr_10: 0.8361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy for attr_1: 0.8594\n",
      "Epoch 8, Validation Accuracy for attr_2: 0.6951\n",
      "Epoch 8, Validation Accuracy for attr_3: 0.8474\n",
      "Epoch 8, Validation Accuracy for attr_4: 0.5705\n",
      "Epoch 8, Validation Accuracy for attr_5: 0.7162\n",
      "Epoch 8, Validation Accuracy for attr_6: 0.9520\n",
      "Epoch 8, Validation Accuracy for attr_7: 0.7391\n",
      "Epoch 8, Validation Accuracy for attr_8: 0.8681\n",
      "Epoch 8, Validation Accuracy for attr_9: 0.6573\n",
      "Epoch 8, Validation Accuracy for attr_10: 0.8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy for attr_1: 0.8597\n",
      "Epoch 9, Validation Accuracy for attr_2: 0.6948\n",
      "Epoch 9, Validation Accuracy for attr_3: 0.8503\n",
      "Epoch 9, Validation Accuracy for attr_4: 0.5701\n",
      "Epoch 9, Validation Accuracy for attr_5: 0.7148\n",
      "Epoch 9, Validation Accuracy for attr_6: 0.9578\n",
      "Epoch 9, Validation Accuracy for attr_7: 0.7395\n",
      "Epoch 9, Validation Accuracy for attr_8: 0.8656\n",
      "Epoch 9, Validation Accuracy for attr_9: 0.6570\n",
      "Epoch 9, Validation Accuracy for attr_10: 0.8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy for attr_1: 0.8605\n",
      "Epoch 10, Validation Accuracy for attr_2: 0.6962\n",
      "Epoch 10, Validation Accuracy for attr_3: 0.8499\n",
      "Epoch 10, Validation Accuracy for attr_4: 0.5730\n",
      "Epoch 10, Validation Accuracy for attr_5: 0.7151\n",
      "Epoch 10, Validation Accuracy for attr_6: 0.9578\n",
      "Epoch 10, Validation Accuracy for attr_7: 0.7380\n",
      "Epoch 10, Validation Accuracy for attr_8: 0.8703\n",
      "Epoch 10, Validation Accuracy for attr_9: 0.6595\n",
      "Epoch 10, Validation Accuracy for attr_10: 0.8354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy per Attribute:\n",
      "Attribute attr_1: 0.8626\n",
      "Attribute attr_2: 0.6966\n",
      "Attribute attr_3: 0.8412\n",
      "Attribute attr_4: 0.5578\n",
      "Attribute attr_5: 0.7028\n",
      "Attribute attr_6: 0.9582\n",
      "Attribute attr_7: 0.7500\n",
      "Attribute attr_8: 0.8681\n",
      "Attribute attr_9: 0.6446\n",
      "Attribute attr_10: 0.8314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "sarees_df = sarees_df.drop(columns=['Category', 'len'])\n",
    "sarees_df = sarees_df.apply(\n",
    "    lambda col: col.fillna('dummy_value') if col.isna().all() \n",
    "    else col.fillna(col.mode()[0]) if col.dtype == 'object' or col.dtype.name == 'category' \n",
    "    else col\n",
    ")\n",
    "\n",
    "# Attribute columns and category mappings\n",
    "attribute_columns_sarees = [f'attr_{i}' for i in range(1, 11)]\n",
    "category_mappings_sarees = {}\n",
    "\n",
    "for col in attribute_columns_sarees:\n",
    "    sarees_df[col] = pd.Categorical(sarees_df[col])\n",
    "    category_mappings_sarees[col] = dict(enumerate(sarees_df[col].cat.categories))\n",
    "    sarees_df[col] = sarees_df[col].cat.codes\n",
    "\n",
    "sarees_df['image_path'] = '/kaggle/input/visual-taxonomy/train_images/' + sarees_df['id'].apply(lambda x: f\"{x:06d}.jpg\")\n",
    "\n",
    "train_df_sarees, temp_df = train_test_split(sarees_df, test_size=0.3, random_state=42)\n",
    "val_df_sarees, test_df_sarees = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define number of classes for each attribute\n",
    "num_classes_per_attribute = {\n",
    "    'attr_1': 4,  \n",
    "    'attr_2': 6,\n",
    "    'attr_3': 3,\n",
    "    'attr_4': 8,\n",
    "    'attr_5': 4,\n",
    "    'attr_6': 3,\n",
    "    'attr_7': 4,\n",
    "    'attr_8': 5,\n",
    "    'attr_9': 9,\n",
    "    'attr_10': 2\n",
    "}\n",
    "\n",
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, num_classes_per_attribute):\n",
    "        super(MultiOutputModel, self).__init__()\n",
    "        \n",
    "        # Load ResNet101 as the base model\n",
    "        self.base_model = models.resnet101(pretrained=True)\n",
    "        \n",
    "        # Save the original fc's in_features before replacing it\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        \n",
    "        # Replace the fully connected layer with an identity layer\n",
    "        self.base_model.fc = nn.Identity()\n",
    "        \n",
    "        # Add dropout\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Create classification heads for each attribute\n",
    "        self.heads = nn.ModuleDict({\n",
    "            attr: nn.Linear(in_features, num_classes)\n",
    "            for attr, num_classes in num_classes_per_attribute.items()\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the base model\n",
    "        features = self.base_model(x)\n",
    "        \n",
    "        # Apply dropout\n",
    "        features = self.dropout(features)\n",
    "        \n",
    "        # Compute logits for each attribute\n",
    "        logits = {attr: head(features) for attr, head in self.heads.items()}\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Initialize the ResNet101-based model\n",
    "model_resnet101_sarees = MultiOutputModel(num_classes_per_attribute)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_str = str(self.df.iloc[idx][\"id\"]).zfill(6)\n",
    "        path = self.df.iloc[idx][\"image_path\"]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels = {attr: torch.tensor(self.df.iloc[idx][attr], dtype=torch.long) for attr in attribute_columns_sarees}\n",
    "        return image, labels\n",
    "\n",
    "# Initialize datasets and data loaders\n",
    "train_dataset = CustomDataset(train_df_sarees, transform=data_augmentation)\n",
    "val_dataset = CustomDataset(val_df_sarees, transform=T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "test_dataset = CustomDataset(test_df_sarees, transform=T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet101_sarees.to(device)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler\n",
    "optimizer = torch.optim.AdamW(model_resnet101_sarees.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training and Validation Loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model_resnet101_sarees.train()\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model_resnet101_sarees(images)\n",
    "            losses = {attr: nn.CrossEntropyLoss()(outputs[attr], labels[attr].to(device)) for attr in labels}\n",
    "            total_loss = sum(losses.values())\n",
    "\n",
    "        scaler.scale(total_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model_resnet101_sarees.eval()\n",
    "    val_corrects = {attr: 0 for attr in attribute_columns_sarees}\n",
    "    val_samples = {attr: 0 for attr in attribute_columns_sarees}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            outputs = model_resnet101_sarees(images)\n",
    "            for attr in labels:\n",
    "                target = labels[attr].to(device)\n",
    "                _, preds = torch.max(outputs[attr], 1)\n",
    "                val_corrects[attr] += torch.sum(preds == target).item()\n",
    "                val_samples[attr] += target.size(0)\n",
    "\n",
    "    # Validation Accuracy per Attribute\n",
    "    for attr in attribute_columns_sarees:\n",
    "        acc = val_corrects[attr] / val_samples[attr] if val_samples[attr] > 0 else 0\n",
    "        print(f\"Epoch {epoch + 1}, Validation Accuracy for {attr}: {acc:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model_resnet101_sarees.eval()\n",
    "test_corrects = {attr: 0 for attr in num_classes_per_attribute.keys()}\n",
    "test_samples = {attr: 0 for attr in num_classes_per_attribute.keys()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        outputs = model_resnet101_sarees(images)\n",
    "        \n",
    "        for attr, target in labels.items():\n",
    "            # Move target to the device\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Get predicted class labels\n",
    "            _, preds = torch.max(outputs[attr], 1)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            test_corrects[attr] += torch.sum(preds == target).item()\n",
    "            test_samples[attr] += target.size(0)\n",
    "\n",
    "print(\"\\nTest Accuracy per Attribute:\")\n",
    "for attr in num_classes_per_attribute.keys():\n",
    "    test_acc = test_corrects[attr] / test_samples[attr] if test_samples[attr] > 0 else 0\n",
    "    print(f\"Attribute {attr}: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T12:22:52.206460Z",
     "iopub.status.busy": "2024-11-16T12:22:52.205344Z",
     "iopub.status.idle": "2024-11-16T12:23:03.355110Z",
     "shell.execute_reply": "2024-11-16T12:23:03.353931Z",
     "shell.execute_reply.started": "2024-11-16T12:22:52.206403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/86 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Testing:  99%|█████████▉| 85/86 [00:10<00:00,  9.60it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for attr_1:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       default       0.59      0.38      0.46       120\n",
      "same as border       0.47      0.13      0.20       254\n",
      " same as saree       0.88      0.97      0.93      2355\n",
      "         solid       0.00      0.00      0.00        23\n",
      "\n",
      "      accuracy                           0.86      2752\n",
      "     macro avg       0.49      0.37      0.40      2752\n",
      "  weighted avg       0.82      0.86      0.83      2752\n",
      "\n",
      "Attribute attr_1 - Accuracy: 0.8626\n",
      "Attribute attr_1 - Precision: 0.8237\n",
      "Attribute attr_1 - Recall: 0.8626\n",
      "Attribute attr_1 - F1 Score: 0.8313\n",
      "\n",
      "Classification Report for attr_2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      default       0.81      0.47      0.59       120\n",
      "    no border       0.50      0.53      0.52        43\n",
      "        solid       0.59      0.73      0.65        62\n",
      "temple border       0.58      0.80      0.67       200\n",
      " woven design       0.63      0.60      0.62       939\n",
      "         zari       0.77      0.77      0.77      1388\n",
      "\n",
      "     accuracy                           0.70      2752\n",
      "    macro avg       0.65      0.65      0.64      2752\n",
      " weighted avg       0.70      0.70      0.70      2752\n",
      "\n",
      "Attribute attr_2 - Accuracy: 0.6966\n",
      "Attribute attr_2 - Precision: 0.7016\n",
      "Attribute attr_2 - Recall: 0.6966\n",
      "Attribute attr_2 - F1 Score: 0.6955\n",
      "\n",
      "Classification Report for attr_3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  big border       0.75      0.79      0.77       842\n",
      "   no border       0.52      0.79      0.63        78\n",
      "small border       0.91      0.87      0.89      1832\n",
      "\n",
      "    accuracy                           0.84      2752\n",
      "   macro avg       0.73      0.82      0.76      2752\n",
      "weighted avg       0.85      0.84      0.84      2752\n",
      "\n",
      "Attribute attr_3 - Accuracy: 0.8412\n",
      "Attribute attr_3 - Precision: 0.8495\n",
      "Attribute attr_3 - Recall: 0.8412\n",
      "Attribute attr_3 - F1 Score: 0.8441\n",
      "\n",
      "Classification Report for attr_4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cream       0.55      0.98      0.70       719\n",
      "     default       0.55      0.81      0.66       595\n",
      "       green       0.75      0.09      0.16        34\n",
      "  multicolor       0.61      0.31      0.41       841\n",
      "   navy blue       0.55      0.63      0.59        62\n",
      "        pink       0.75      0.06      0.12        48\n",
      "       white       0.68      0.06      0.11       421\n",
      "      yellow       0.38      0.53      0.44        32\n",
      "\n",
      "    accuracy                           0.56      2752\n",
      "   macro avg       0.60      0.43      0.40      2752\n",
      "weighted avg       0.59      0.56      0.49      2752\n",
      "\n",
      "Attribute attr_4 - Accuracy: 0.5578\n",
      "Attribute attr_4 - Precision: 0.5906\n",
      "Attribute attr_4 - Recall: 0.5578\n",
      "Attribute attr_4 - F1 Score: 0.4897\n",
      "\n",
      "Classification Report for attr_5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daily       0.51      0.21      0.29       208\n",
      "       party       0.75      0.91      0.82      1642\n",
      " traditional       0.60      0.45      0.51       775\n",
      "     wedding       0.46      0.35      0.40       127\n",
      "\n",
      "    accuracy                           0.70      2752\n",
      "   macro avg       0.58      0.48      0.51      2752\n",
      "weighted avg       0.68      0.70      0.68      2752\n",
      "\n",
      "Attribute attr_5 - Accuracy: 0.7028\n",
      "Attribute attr_5 - Precision: 0.6778\n",
      "Attribute attr_5 - Recall: 0.7028\n",
      "Attribute attr_5 - F1 Score: 0.6770\n",
      "\n",
      "Classification Report for attr_6:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "            default       0.45      0.13      0.20        71\n",
      "           jacquard       0.97      0.99      0.98      2642\n",
      "tassels and latkans       0.43      0.38      0.41        39\n",
      "\n",
      "           accuracy                           0.96      2752\n",
      "          macro avg       0.62      0.50      0.53      2752\n",
      "       weighted avg       0.95      0.96      0.95      2752\n",
      "\n",
      "Attribute attr_6 - Accuracy: 0.9582\n",
      "Attribute attr_6 - Precision: 0.9478\n",
      "Attribute attr_6 - Recall: 0.9582\n",
      "Attribute attr_6 - F1 Score: 0.9506\n",
      "\n",
      "Classification Report for attr_7:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      default       0.00      0.00      0.00        54\n",
      "same as saree       0.50      0.14      0.22       323\n",
      " woven design       0.80      0.91      0.85      1987\n",
      "   zari woven       0.52      0.54      0.53       388\n",
      "\n",
      "     accuracy                           0.75      2752\n",
      "    macro avg       0.45      0.40      0.40      2752\n",
      " weighted avg       0.71      0.75      0.72      2752\n",
      "\n",
      "Attribute attr_7 - Accuracy: 0.7500\n",
      "Attribute attr_7 - Precision: 0.7108\n",
      "Attribute attr_7 - Recall: 0.7500\n",
      "Attribute attr_7 - F1 Score: 0.7160\n",
      "\n",
      "Classification Report for attr_8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     default       0.52      0.10      0.17       119\n",
      "     printed       0.67      0.06      0.11        35\n",
      "       solid       0.55      0.90      0.69       177\n",
      "woven design       0.61      0.42      0.50       119\n",
      "  zari woven       0.92      0.94      0.93      2302\n",
      "\n",
      "    accuracy                           0.87      2752\n",
      "   macro avg       0.65      0.48      0.48      2752\n",
      "weighted avg       0.86      0.87      0.85      2752\n",
      "\n",
      "Attribute attr_8 - Accuracy: 0.8681\n",
      "Attribute attr_8 - Precision: 0.8620\n",
      "Attribute attr_8 - Recall: 0.8681\n",
      "Attribute attr_8 - F1 Score: 0.8521\n",
      "\n",
      "Classification Report for attr_9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    applique       0.71      0.05      0.10        95\n",
      "   botanical       0.00      0.00      0.00        38\n",
      "     checked       0.38      0.14      0.20        37\n",
      "     default       0.65      0.73      0.68      1060\n",
      "    elephant       0.69      0.90      0.78       105\n",
      "ethnic motif       0.46      0.20      0.28       453\n",
      "      floral       0.68      0.88      0.77       396\n",
      "     peacock       0.74      0.81      0.77       386\n",
      "       solid       0.55      0.80      0.65       182\n",
      "\n",
      "    accuracy                           0.64      2752\n",
      "   macro avg       0.54      0.50      0.47      2752\n",
      "weighted avg       0.62      0.64      0.61      2752\n",
      "\n",
      "Attribute attr_9 - Accuracy: 0.6446\n",
      "Attribute attr_9 - Precision: 0.6183\n",
      "Attribute attr_9 - Recall: 0.6446\n",
      "Attribute attr_9 - F1 Score: 0.6074\n",
      "\n",
      "Classification Report for attr_10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.83      1.00      0.91      2291\n",
      "         yes       0.36      0.01      0.02       461\n",
      "\n",
      "    accuracy                           0.83      2752\n",
      "   macro avg       0.60      0.50      0.46      2752\n",
      "weighted avg       0.75      0.83      0.76      2752\n",
      "\n",
      "Attribute attr_10 - Accuracy: 0.8314\n",
      "Attribute attr_10 - Precision: 0.7546\n",
      "Attribute attr_10 - Recall: 0.8314\n",
      "Attribute attr_10 - F1 Score: 0.7586\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Accuracy: 0.7713\n",
      "Overall Precision: 0.7693\n",
      "Overall Recall: 0.7713\n",
      "Overall F1 Score: 0.7685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model_resnet101_sarees.eval()\n",
    "\n",
    "# Prepare lists to store predictions and true labels for all attributes\n",
    "true_labels_all = {attr: [] for attr in num_classes_per_attribute.keys()}\n",
    "pred_labels_all = {attr: [] for attr in num_classes_per_attribute.keys()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        outputs = model_resnet101_sarees(images)\n",
    "        \n",
    "        for attr, target in labels.items():\n",
    "            # Move target to the device\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Get predicted class labels\n",
    "            _, preds = torch.max(outputs[attr], 1)\n",
    "            \n",
    "            # Store true labels and predicted labels for each attribute\n",
    "            true_labels_all[attr].extend(target.cpu().numpy())\n",
    "            pred_labels_all[attr].extend(preds.cpu().numpy())\n",
    "\n",
    "# Print test accuracy, precision, recall, F1 score, and classification report for each attribute\n",
    "for attr in num_classes_per_attribute.keys():\n",
    "    true_labels = true_labels_all[attr]\n",
    "    pred_labels = pred_labels_all[attr]\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    \n",
    "    # Compute precision, recall, and F1 score\n",
    "    precision = precision_score(true_labels, pred_labels, average='weighted', zero_division=1)\n",
    "    recall = recall_score(true_labels, pred_labels, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(true_labels, pred_labels, average='weighted', zero_division=1)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"\\nClassification Report for {attr}:\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=category_mappings_sarees[attr].values()))\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print(f\"Attribute {attr} - Accuracy: {acc:.4f}\")\n",
    "    print(f\"Attribute {attr} - Precision: {precision:.4f}\")\n",
    "    print(f\"Attribute {attr} - Recall: {recall:.4f}\")\n",
    "    print(f\"Attribute {attr} - F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate overall metrics across all attributes\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "for attr in num_classes_per_attribute.keys():\n",
    "    all_true_labels.extend(true_labels_all[attr])\n",
    "    all_pred_labels.extend(pred_labels_all[attr])\n",
    "\n",
    "# Compute overall accuracy, precision, recall, and F1 score\n",
    "overall_acc = accuracy_score(all_true_labels, all_pred_labels)\n",
    "overall_precision = precision_score(all_true_labels, all_pred_labels, average='weighted', zero_division=1)\n",
    "overall_recall = recall_score(all_true_labels, all_pred_labels, average='weighted', zero_division=1)\n",
    "overall_f1 = f1_score(all_true_labels, all_pred_labels, average='weighted', zero_division=1)\n",
    "\n",
    "# Print overall metrics\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Overall Accuracy: {overall_acc:.4f}\")\n",
    "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T09:04:51.131919Z",
     "iopub.status.busy": "2024-11-16T09:04:51.131418Z",
     "iopub.status.idle": "2024-11-16T09:12:45.851922Z",
     "shell.execute_reply": "2024-11-16T09:12:45.850750Z",
     "shell.execute_reply.started": "2024-11-16T09:04:51.131875Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Training Epoch 1/10:   0%|          | 0/150 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training Epoch 1/10: 100%|██████████| 150/150 [00:42<00:00,  3.47it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.6862\n",
      "Validation Accuracy for attr_2: 0.8788\n",
      "Validation Accuracy for attr_3: 0.8192\n",
      "Validation Accuracy for attr_4: 0.9394\n",
      "Validation Accuracy for attr_5: 0.9022\n",
      "Validation Accuracy for attr_6: 0.7605\n",
      "Validation Accuracy for attr_7: 0.7370\n",
      "Validation Accuracy for attr_8: 0.9159\n",
      "Validation Accuracy for attr_9: 0.9736\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.7322\n",
      "Validation Accuracy for attr_2: 0.8925\n",
      "Validation Accuracy for attr_3: 0.8143\n",
      "Validation Accuracy for attr_4: 0.9394\n",
      "Validation Accuracy for attr_5: 0.9081\n",
      "Validation Accuracy for attr_6: 0.7507\n",
      "Validation Accuracy for attr_7: 0.7214\n",
      "Validation Accuracy for attr_8: 0.9413\n",
      "Validation Accuracy for attr_9: 0.9932\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.7713\n",
      "Validation Accuracy for attr_2: 0.9013\n",
      "Validation Accuracy for attr_3: 0.8270\n",
      "Validation Accuracy for attr_4: 0.9443\n",
      "Validation Accuracy for attr_5: 0.9071\n",
      "Validation Accuracy for attr_6: 0.7595\n",
      "Validation Accuracy for attr_7: 0.7419\n",
      "Validation Accuracy for attr_8: 0.9541\n",
      "Validation Accuracy for attr_9: 0.9971\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.7830\n",
      "Validation Accuracy for attr_2: 0.8895\n",
      "Validation Accuracy for attr_3: 0.8123\n",
      "Validation Accuracy for attr_4: 0.9423\n",
      "Validation Accuracy for attr_5: 0.9120\n",
      "Validation Accuracy for attr_6: 0.7644\n",
      "Validation Accuracy for attr_7: 0.7674\n",
      "Validation Accuracy for attr_8: 0.9492\n",
      "Validation Accuracy for attr_9: 0.9932\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.8182\n",
      "Validation Accuracy for attr_2: 0.9042\n",
      "Validation Accuracy for attr_3: 0.8231\n",
      "Validation Accuracy for attr_4: 0.9384\n",
      "Validation Accuracy for attr_5: 0.9169\n",
      "Validation Accuracy for attr_6: 0.7722\n",
      "Validation Accuracy for attr_7: 0.7527\n",
      "Validation Accuracy for attr_8: 0.9580\n",
      "Validation Accuracy for attr_9: 0.9941\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.8133\n",
      "Validation Accuracy for attr_2: 0.9062\n",
      "Validation Accuracy for attr_3: 0.8182\n",
      "Validation Accuracy for attr_4: 0.9443\n",
      "Validation Accuracy for attr_5: 0.9238\n",
      "Validation Accuracy for attr_6: 0.7693\n",
      "Validation Accuracy for attr_7: 0.7625\n",
      "Validation Accuracy for attr_8: 0.9609\n",
      "Validation Accuracy for attr_9: 0.9961\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.8231\n",
      "Validation Accuracy for attr_2: 0.8993\n",
      "Validation Accuracy for attr_3: 0.8299\n",
      "Validation Accuracy for attr_4: 0.9394\n",
      "Validation Accuracy for attr_5: 0.9198\n",
      "Validation Accuracy for attr_6: 0.7732\n",
      "Validation Accuracy for attr_7: 0.7664\n",
      "Validation Accuracy for attr_8: 0.9589\n",
      "Validation Accuracy for attr_9: 0.9951\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.8240\n",
      "Validation Accuracy for attr_2: 0.9013\n",
      "Validation Accuracy for attr_3: 0.8260\n",
      "Validation Accuracy for attr_4: 0.9423\n",
      "Validation Accuracy for attr_5: 0.9218\n",
      "Validation Accuracy for attr_6: 0.7732\n",
      "Validation Accuracy for attr_7: 0.7742\n",
      "Validation Accuracy for attr_8: 0.9570\n",
      "Validation Accuracy for attr_9: 0.9961\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.8299\n",
      "Validation Accuracy for attr_2: 0.9081\n",
      "Validation Accuracy for attr_3: 0.8358\n",
      "Validation Accuracy for attr_4: 0.9404\n",
      "Validation Accuracy for attr_5: 0.9179\n",
      "Validation Accuracy for attr_6: 0.7810\n",
      "Validation Accuracy for attr_7: 0.7693\n",
      "Validation Accuracy for attr_8: 0.9589\n",
      "Validation Accuracy for attr_9: 0.9971\n",
      "Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for attr_1: 0.8309\n",
      "Validation Accuracy for attr_2: 0.9101\n",
      "Validation Accuracy for attr_3: 0.8319\n",
      "Validation Accuracy for attr_4: 0.9433\n",
      "Validation Accuracy for attr_5: 0.9238\n",
      "Validation Accuracy for attr_6: 0.7791\n",
      "Validation Accuracy for attr_7: 0.7654\n",
      "Validation Accuracy for attr_8: 0.9580\n",
      "Validation Accuracy for attr_9: 0.9961\n",
      "Validation Accuracy for attr_10: 1.0000\n",
      "Test Accuracy for attr_1: 0.7891\n",
      "Test Accuracy for attr_2: 0.8926\n",
      "Test Accuracy for attr_3: 0.8154\n",
      "Test Accuracy for attr_4: 0.9355\n",
      "Test Accuracy for attr_5: 0.9355\n",
      "Test Accuracy for attr_6: 0.7734\n",
      "Test Accuracy for attr_7: 0.7725\n",
      "Test Accuracy for attr_8: 0.9629\n",
      "Test Accuracy for attr_9: 0.9932\n",
      "Test Accuracy for attr_10: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "kurtis_df = kurtis_df.drop(columns=['Category', 'len'])\n",
    "kurtis_df = kurtis_df.apply(\n",
    "    lambda col: col.fillna('dummy_value') if col.isna().all() \n",
    "    else col.fillna(col.mode()[0]) if col.dtype == 'object' or col.dtype.name == 'category' \n",
    "    else col\n",
    ")\n",
    "\n",
    "attribute_columns_kurtis = [f'attr_{i}' for i in range(1, 11)]\n",
    "category_mappings_kurtis = {}\n",
    "\n",
    "for col in attribute_columns_kurtis:\n",
    "    kurtis_df[col] = pd.Categorical(kurtis_df[col])\n",
    "    category_mappings_kurtis[col] = dict(enumerate(kurtis_df[col].cat.categories))\n",
    "    kurtis_df[col] = kurtis_df[col].cat.codes\n",
    "\n",
    "kurtis_df['image_path'] = '/kaggle/input/visual-taxonomy/train_images/' + kurtis_df['id'].apply(lambda x: f\"{x:06d}.jpg\")\n",
    "\n",
    "# Split dataset\n",
    "train_df_kurtis, temp_df_kurtis = train_test_split(kurtis_df, test_size=0.3, random_state=42)\n",
    "val_df_kurtis, test_df_kurtis = train_test_split(temp_df_kurtis, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define number of classes for each attribute\n",
    "num_classes_per_attribute_kurtis = {\n",
    "    'attr_1': 13, 'attr_2': 2, 'attr_3': 2, 'attr_4': 2, 'attr_5': 2,\n",
    "    'attr_6': 2, 'attr_7': 2, 'attr_8': 3, 'attr_9': 2, 'attr_10': 1\n",
    "}\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx][\"image_path\"]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels = {}\n",
    "        for attr in attribute_columns_kurtis:\n",
    "            labels[attr] = torch.tensor(self.df.iloc[idx][attr], dtype=torch.long)\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "# Data Augmentation and Loaders\n",
    "data_augmentation = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset_kurtis = CustomDataset(train_df_kurtis, transform=data_augmentation)\n",
    "val_dataset_kurtis = CustomDataset(val_df_kurtis, transform=val_test_transforms)\n",
    "test_dataset_kurtis = CustomDataset(test_df_kurtis, transform=val_test_transforms)\n",
    "\n",
    "train_loader_kurtis = DataLoader(train_dataset_kurtis, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader_kurtis = DataLoader(val_dataset_kurtis, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader_kurtis = DataLoader(test_dataset_kurtis, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Model Definition\n",
    "class MultiOutputResNet(nn.Module):\n",
    "    def __init__(self, num_classes_per_attribute):\n",
    "        super(MultiOutputResNet, self).__init__()\n",
    "        base_model = resnet101(pretrained=True)\n",
    "        self.base = nn.Sequential(*list(base_model.children())[:-2])\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.heads = nn.ModuleDict({\n",
    "            attr: nn.Linear(2048, num_classes)\n",
    "            for attr, num_classes in num_classes_per_attribute.items()\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        logits = {attr: self.heads[attr](x) for attr in self.heads}\n",
    "        return logits\n",
    "\n",
    "model_kurtis = MultiOutputResNet(num_classes_per_attribute_kurtis)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_kurtis.to(device)\n",
    "\n",
    "# Optimizer, Scheduler, and Loss\n",
    "optimizer = optim.AdamW(model_kurtis.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model_kurtis.train()\n",
    "    for images, labels in tqdm(train_loader_kurtis, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_kurtis(images)\n",
    "        total_loss = 0\n",
    "        for attr in labels:\n",
    "            target = labels[attr].to(device)\n",
    "            loss = loss_fn(outputs[attr], target)\n",
    "            total_loss += loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model_kurtis.eval()\n",
    "    val_corrects = {attr: 0 for attr in attribute_columns_kurtis}\n",
    "    val_samples = {attr: 0 for attr in attribute_columns_kurtis}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader_kurtis:\n",
    "            images = images.to(device)\n",
    "            outputs = model_kurtis(images)\n",
    "\n",
    "            for attr in labels:\n",
    "                target = labels[attr].to(device)\n",
    "                _, preds = torch.max(outputs[attr], 1)\n",
    "                val_corrects[attr] += (preds == target).sum().item()\n",
    "                val_samples[attr] += target.size(0)\n",
    "\n",
    "    for attr in attribute_columns_kurtis:\n",
    "        acc = val_corrects[attr] / val_samples[attr] if val_samples[attr] > 0 else 0\n",
    "        print(f\"Validation Accuracy for {attr}: {acc:.4f}\")\n",
    "\n",
    "# Testing\n",
    "model_kurtis.eval()\n",
    "test_corrects = {attr: 0 for attr in attribute_columns_kurtis}\n",
    "test_samples = {attr: 0 for attr in attribute_columns_kurtis}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_kurtis:\n",
    "        images = images.to(device)\n",
    "        outputs = model_kurtis(images)\n",
    "\n",
    "        for attr in labels:\n",
    "            target = labels[attr].to(device)\n",
    "            _, preds = torch.max(outputs[attr], 1)\n",
    "            test_corrects[attr] += (preds == target).sum().item()\n",
    "            test_samples[attr] += target.size(0)\n",
    "\n",
    "for attr in attribute_columns_kurtis:\n",
    "    acc = test_corrects[attr] / test_samples[attr] if test_samples[attr] > 0 else 0\n",
    "    print(f\"Test Accuracy for {attr}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:00:44.853831Z",
     "iopub.status.busy": "2024-11-16T10:00:44.853219Z",
     "iopub.status.idle": "2024-11-16T10:08:41.055649Z",
     "shell.execute_reply": "2024-11-16T10:08:41.054478Z",
     "shell.execute_reply.started": "2024-11-16T10:00:44.853783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_30/3393492256.py:141: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Training Epoch 1/10:   0%|          | 0/159 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_30/3393492256.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training Epoch 1/10: 100%|██████████| 159/159 [00:42<00:00,  3.96it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy for attr_1: 0.6257\n",
      "Epoch 1, Validation Accuracy for attr_2: 0.8761\n",
      "Epoch 1, Validation Accuracy for attr_3: 0.8321\n",
      "Epoch 1, Validation Accuracy for attr_4: 0.7670\n",
      "Epoch 1, Validation Accuracy for attr_5: 0.9578\n",
      "Epoch 1, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 1, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 1, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 1, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 1, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy for attr_1: 0.6367\n",
      "Epoch 2, Validation Accuracy for attr_2: 0.8899\n",
      "Epoch 2, Validation Accuracy for attr_3: 0.8486\n",
      "Epoch 2, Validation Accuracy for attr_4: 0.7963\n",
      "Epoch 2, Validation Accuracy for attr_5: 0.9716\n",
      "Epoch 2, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 2, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 2, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 2, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 2, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy for attr_1: 0.6514\n",
      "Epoch 3, Validation Accuracy for attr_2: 0.8844\n",
      "Epoch 3, Validation Accuracy for attr_3: 0.8450\n",
      "Epoch 3, Validation Accuracy for attr_4: 0.7853\n",
      "Epoch 3, Validation Accuracy for attr_5: 0.9725\n",
      "Epoch 3, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 3, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 3, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 3, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 3, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy for attr_1: 0.6321\n",
      "Epoch 4, Validation Accuracy for attr_2: 0.8734\n",
      "Epoch 4, Validation Accuracy for attr_3: 0.8532\n",
      "Epoch 4, Validation Accuracy for attr_4: 0.7679\n",
      "Epoch 4, Validation Accuracy for attr_5: 0.9734\n",
      "Epoch 4, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 4, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 4, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 4, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 4, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy for attr_1: 0.6541\n",
      "Epoch 5, Validation Accuracy for attr_2: 0.8844\n",
      "Epoch 5, Validation Accuracy for attr_3: 0.8413\n",
      "Epoch 5, Validation Accuracy for attr_4: 0.7890\n",
      "Epoch 5, Validation Accuracy for attr_5: 0.9697\n",
      "Epoch 5, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 5, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 5, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 5, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 5, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy for attr_1: 0.6440\n",
      "Epoch 6, Validation Accuracy for attr_2: 0.8789\n",
      "Epoch 6, Validation Accuracy for attr_3: 0.8404\n",
      "Epoch 6, Validation Accuracy for attr_4: 0.7615\n",
      "Epoch 6, Validation Accuracy for attr_5: 0.9679\n",
      "Epoch 6, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 6, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 6, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 6, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 6, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy for attr_1: 0.6550\n",
      "Epoch 7, Validation Accuracy for attr_2: 0.8780\n",
      "Epoch 7, Validation Accuracy for attr_3: 0.8422\n",
      "Epoch 7, Validation Accuracy for attr_4: 0.7826\n",
      "Epoch 7, Validation Accuracy for attr_5: 0.9661\n",
      "Epoch 7, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 7, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 7, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 7, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 7, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy for attr_1: 0.6633\n",
      "Epoch 8, Validation Accuracy for attr_2: 0.8661\n",
      "Epoch 8, Validation Accuracy for attr_3: 0.8440\n",
      "Epoch 8, Validation Accuracy for attr_4: 0.7688\n",
      "Epoch 8, Validation Accuracy for attr_5: 0.9679\n",
      "Epoch 8, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 8, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 8, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 8, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 8, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy for attr_1: 0.6606\n",
      "Epoch 9, Validation Accuracy for attr_2: 0.8697\n",
      "Epoch 9, Validation Accuracy for attr_3: 0.8385\n",
      "Epoch 9, Validation Accuracy for attr_4: 0.7771\n",
      "Epoch 9, Validation Accuracy for attr_5: 0.9688\n",
      "Epoch 9, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 9, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 9, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 9, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 9, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy for attr_1: 0.6624\n",
      "Epoch 10, Validation Accuracy for attr_2: 0.8661\n",
      "Epoch 10, Validation Accuracy for attr_3: 0.8450\n",
      "Epoch 10, Validation Accuracy for attr_4: 0.7771\n",
      "Epoch 10, Validation Accuracy for attr_5: 0.9688\n",
      "Epoch 10, Validation Accuracy for attr_6: 1.0000\n",
      "Epoch 10, Validation Accuracy for attr_7: 1.0000\n",
      "Epoch 10, Validation Accuracy for attr_8: 1.0000\n",
      "Epoch 10, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 10, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy per Attribute:\n",
      "Attribute attr_1: 0.6664\n",
      "Attribute attr_2: 0.8698\n",
      "Attribute attr_3: 0.8368\n",
      "Attribute attr_4: 0.7938\n",
      "Attribute attr_5: 0.9578\n",
      "Attribute attr_6: 1.0000\n",
      "Attribute attr_7: 1.0000\n",
      "Attribute attr_8: 1.0000\n",
      "Attribute attr_9: 1.0000\n",
      "Attribute attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Prepare and process data\n",
    "men_tshirts_df = men_tshirts_df.drop(columns=['Category', 'len'])\n",
    "men_tshirts_df = men_tshirts_df.apply(\n",
    "    lambda col: col.fillna('dummy_value') if col.isna().all() \n",
    "    else col.fillna(col.mode()[0]) if col.dtype == 'object' or col.dtype.name == 'category' \n",
    "    else col\n",
    ")\n",
    "\n",
    "# Define attribute columns and category mappings\n",
    "attribute_columns_men_tshirts = [f'attr_{i}' for i in range(1, 11)]\n",
    "category_mappings_men_tshirts = {}\n",
    "\n",
    "for col in attribute_columns_men_tshirts:\n",
    "    men_tshirts_df[col] = pd.Categorical(men_tshirts_df[col])\n",
    "    category_mappings_men_tshirts[col] = dict(enumerate(men_tshirts_df[col].cat.categories))\n",
    "    men_tshirts_df[col] = men_tshirts_df[col].cat.codes\n",
    "\n",
    "men_tshirts_df['image_path'] = '/kaggle/input/visual-taxonomy/train_images/' + men_tshirts_df['id'].apply(lambda x: f\"{x:06d}.jpg\")\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_df_men_tshirts, temp_df = train_test_split(men_tshirts_df, test_size=0.3, random_state=42)\n",
    "val_df_men_tshirts, test_df_men_tshirts = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define number of classes for each attribute\n",
    "num_classes_per_attribute = {\n",
    "    'attr_1': 4,\n",
    "    'attr_2': 2,\n",
    "    'attr_3': 2,\n",
    "    'attr_4': 3,\n",
    "    'attr_5': 3,\n",
    "    'attr_6': 1,\n",
    "    'attr_7': 1,\n",
    "    'attr_8': 1,\n",
    "    'attr_9': 1,\n",
    "    'attr_10': 1\n",
    "}\n",
    "\n",
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, num_classes_per_attribute):\n",
    "        super(MultiOutputModel, self).__init__()\n",
    "        \n",
    "        # Load ResNet101 as the base model\n",
    "        self.base_model = models.resnet101(pretrained=True)\n",
    "        \n",
    "        # Save the original fc's in_features before replacing it\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        \n",
    "        # Replace the fully connected layer with an identity layer\n",
    "        self.base_model.fc = nn.Identity()\n",
    "        \n",
    "        # Add dropout\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Create classification heads for each attribute\n",
    "        self.heads = nn.ModuleDict({\n",
    "            attr: nn.Linear(in_features, num_classes)\n",
    "            for attr, num_classes in num_classes_per_attribute.items()\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the base model\n",
    "        features = self.base_model(x)\n",
    "        \n",
    "        # Apply dropout\n",
    "        features = self.dropout(features)\n",
    "        \n",
    "        # Compute logits for each attribute\n",
    "        logits = {attr: head(features) for attr, head in self.heads.items()}\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Initialize the ResNet101-based model\n",
    "model_resnet101 = MultiOutputModel(num_classes_per_attribute)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_str = str(self.df.iloc[idx][\"id\"]).zfill(6)\n",
    "        path = self.df.iloc[idx][\"image_path\"]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels = {attr: torch.tensor(self.df.iloc[idx][attr], dtype=torch.long) for attr in attribute_columns_men_tshirts}\n",
    "        return image, labels\n",
    "\n",
    "# Initialize datasets and data loaders\n",
    "train_dataset = CustomDataset(train_df_men_tshirts, transform=data_augmentation)\n",
    "val_dataset = CustomDataset(val_df_men_tshirts, transform=T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "test_dataset = CustomDataset(test_df_men_tshirts, transform=T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet101.to(device)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler\n",
    "optimizer = torch.optim.AdamW(model_resnet101.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training and Validation Loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model_resnet101.train()\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model_resnet101(images)\n",
    "            losses = {attr: nn.CrossEntropyLoss()(outputs[attr], labels[attr].to(device)) for attr in labels}\n",
    "            total_loss = sum(losses.values())\n",
    "\n",
    "        scaler.scale(total_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model_resnet101.eval()\n",
    "    val_corrects = {attr: 0 for attr in attribute_columns_men_tshirts}\n",
    "    val_samples = {attr: 0 for attr in attribute_columns_men_tshirts}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            outputs = model_resnet101(images)\n",
    "            for attr in labels:\n",
    "                target = labels[attr].to(device)\n",
    "                _, preds = torch.max(outputs[attr], 1)\n",
    "                val_corrects[attr] += torch.sum(preds == target).item()\n",
    "                val_samples[attr] += target.size(0)\n",
    "\n",
    "    # Validation Accuracy per Attribute\n",
    "    for attr in attribute_columns_men_tshirts:\n",
    "        acc = val_corrects[attr] / val_samples[attr] if val_samples[attr] > 0 else 0\n",
    "        print(f\"Epoch {epoch + 1}, Validation Accuracy for {attr}: {acc:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model_resnet101.eval()\n",
    "test_corrects = {attr: 0 for attr in num_classes_per_attribute.keys()}\n",
    "test_samples = {attr: 0 for attr in num_classes_per_attribute.keys()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        outputs = model_resnet101(images)\n",
    "        \n",
    "        for attr, target in labels.items():\n",
    "            # Move target to the device\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Get predicted class labels\n",
    "            _, preds = torch.max(outputs[attr], 1)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            test_corrects[attr] += torch.sum(preds == target).item()\n",
    "            test_samples[attr] += target.size(0)\n",
    "\n",
    "# Print test accuracy for each attribute\n",
    "print(\"\\nTest Accuracy per Attribute:\")\n",
    "for attr in num_classes_per_attribute.keys():\n",
    "    test_acc = test_corrects[attr] / test_samples[attr] if test_samples[attr] > 0 else 0\n",
    "    print(f\"Attribute {attr}: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:08:41.058690Z",
     "iopub.status.busy": "2024-11-16T10:08:41.058219Z",
     "iopub.status.idle": "2024-11-16T10:29:22.180366Z",
     "shell.execute_reply": "2024-11-16T10:29:22.179164Z",
     "shell.execute_reply.started": "2024-11-16T10:08:41.058638Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_30/1260821195.py:141: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Training Epoch 1/10:   0%|          | 0/416 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_30/1260821195.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training Epoch 1/10: 100%|██████████| 416/416 [01:51<00:00,  4.10it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy for attr_1: 0.5826\n",
      "Epoch 1, Validation Accuracy for attr_2: 0.7320\n",
      "Epoch 1, Validation Accuracy for attr_3: 0.8492\n",
      "Epoch 1, Validation Accuracy for attr_4: 0.6777\n",
      "Epoch 1, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 1, Validation Accuracy for attr_6: 0.8913\n",
      "Epoch 1, Validation Accuracy for attr_7: 0.8285\n",
      "Epoch 1, Validation Accuracy for attr_8: 0.7973\n",
      "Epoch 1, Validation Accuracy for attr_9: 0.8095\n",
      "Epoch 1, Validation Accuracy for attr_10: 0.8141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy for attr_1: 0.6359\n",
      "Epoch 2, Validation Accuracy for attr_2: 0.7527\n",
      "Epoch 2, Validation Accuracy for attr_3: 0.8446\n",
      "Epoch 2, Validation Accuracy for attr_4: 0.6980\n",
      "Epoch 2, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 2, Validation Accuracy for attr_6: 0.8846\n",
      "Epoch 2, Validation Accuracy for attr_7: 0.8285\n",
      "Epoch 2, Validation Accuracy for attr_8: 0.8120\n",
      "Epoch 2, Validation Accuracy for attr_9: 0.8257\n",
      "Epoch 2, Validation Accuracy for attr_10: 0.8155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy for attr_1: 0.6328\n",
      "Epoch 3, Validation Accuracy for attr_2: 0.7468\n",
      "Epoch 3, Validation Accuracy for attr_3: 0.8506\n",
      "Epoch 3, Validation Accuracy for attr_4: 0.7085\n",
      "Epoch 3, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 3, Validation Accuracy for attr_6: 0.8895\n",
      "Epoch 3, Validation Accuracy for attr_7: 0.8369\n",
      "Epoch 3, Validation Accuracy for attr_8: 0.8173\n",
      "Epoch 3, Validation Accuracy for attr_9: 0.8334\n",
      "Epoch 3, Validation Accuracy for attr_10: 0.8162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy for attr_1: 0.6629\n",
      "Epoch 4, Validation Accuracy for attr_2: 0.7573\n",
      "Epoch 4, Validation Accuracy for attr_3: 0.8513\n",
      "Epoch 4, Validation Accuracy for attr_4: 0.7236\n",
      "Epoch 4, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 4, Validation Accuracy for attr_6: 0.8990\n",
      "Epoch 4, Validation Accuracy for attr_7: 0.8373\n",
      "Epoch 4, Validation Accuracy for attr_8: 0.8246\n",
      "Epoch 4, Validation Accuracy for attr_9: 0.8351\n",
      "Epoch 4, Validation Accuracy for attr_10: 0.8180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy for attr_1: 0.6731\n",
      "Epoch 5, Validation Accuracy for attr_2: 0.7636\n",
      "Epoch 5, Validation Accuracy for attr_3: 0.8530\n",
      "Epoch 5, Validation Accuracy for attr_4: 0.7197\n",
      "Epoch 5, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 5, Validation Accuracy for attr_6: 0.9004\n",
      "Epoch 5, Validation Accuracy for attr_7: 0.8418\n",
      "Epoch 5, Validation Accuracy for attr_8: 0.8278\n",
      "Epoch 5, Validation Accuracy for attr_9: 0.8355\n",
      "Epoch 5, Validation Accuracy for attr_10: 0.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy for attr_1: 0.6749\n",
      "Epoch 6, Validation Accuracy for attr_2: 0.7576\n",
      "Epoch 6, Validation Accuracy for attr_3: 0.8590\n",
      "Epoch 6, Validation Accuracy for attr_4: 0.7219\n",
      "Epoch 6, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 6, Validation Accuracy for attr_6: 0.9011\n",
      "Epoch 6, Validation Accuracy for attr_7: 0.8457\n",
      "Epoch 6, Validation Accuracy for attr_8: 0.8299\n",
      "Epoch 6, Validation Accuracy for attr_9: 0.8478\n",
      "Epoch 6, Validation Accuracy for attr_10: 0.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy for attr_1: 0.6770\n",
      "Epoch 7, Validation Accuracy for attr_2: 0.7664\n",
      "Epoch 7, Validation Accuracy for attr_3: 0.8597\n",
      "Epoch 7, Validation Accuracy for attr_4: 0.7320\n",
      "Epoch 7, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 7, Validation Accuracy for attr_6: 0.9000\n",
      "Epoch 7, Validation Accuracy for attr_7: 0.8464\n",
      "Epoch 7, Validation Accuracy for attr_8: 0.8239\n",
      "Epoch 7, Validation Accuracy for attr_9: 0.8373\n",
      "Epoch 7, Validation Accuracy for attr_10: 0.8218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy for attr_1: 0.6906\n",
      "Epoch 8, Validation Accuracy for attr_2: 0.7639\n",
      "Epoch 8, Validation Accuracy for attr_3: 0.8527\n",
      "Epoch 8, Validation Accuracy for attr_4: 0.7345\n",
      "Epoch 8, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 8, Validation Accuracy for attr_6: 0.9011\n",
      "Epoch 8, Validation Accuracy for attr_7: 0.8453\n",
      "Epoch 8, Validation Accuracy for attr_8: 0.8292\n",
      "Epoch 8, Validation Accuracy for attr_9: 0.8485\n",
      "Epoch 8, Validation Accuracy for attr_10: 0.8211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy for attr_1: 0.6917\n",
      "Epoch 9, Validation Accuracy for attr_2: 0.7713\n",
      "Epoch 9, Validation Accuracy for attr_3: 0.8558\n",
      "Epoch 9, Validation Accuracy for attr_4: 0.7397\n",
      "Epoch 9, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 9, Validation Accuracy for attr_6: 0.9021\n",
      "Epoch 9, Validation Accuracy for attr_7: 0.8443\n",
      "Epoch 9, Validation Accuracy for attr_8: 0.8358\n",
      "Epoch 9, Validation Accuracy for attr_9: 0.8453\n",
      "Epoch 9, Validation Accuracy for attr_10: 0.8232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy for attr_1: 0.6882\n",
      "Epoch 10, Validation Accuracy for attr_2: 0.7710\n",
      "Epoch 10, Validation Accuracy for attr_3: 0.8544\n",
      "Epoch 10, Validation Accuracy for attr_4: 0.7373\n",
      "Epoch 10, Validation Accuracy for attr_5: 0.9902\n",
      "Epoch 10, Validation Accuracy for attr_6: 0.9011\n",
      "Epoch 10, Validation Accuracy for attr_7: 0.8460\n",
      "Epoch 10, Validation Accuracy for attr_8: 0.8327\n",
      "Epoch 10, Validation Accuracy for attr_9: 0.8481\n",
      "Epoch 10, Validation Accuracy for attr_10: 0.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy per Attribute:\n",
      "Attribute attr_1: 0.6738\n",
      "Attribute attr_2: 0.7685\n",
      "Attribute attr_3: 0.8730\n",
      "Attribute attr_4: 0.7531\n",
      "Attribute attr_5: 0.9895\n",
      "Attribute attr_6: 0.9004\n",
      "Attribute attr_7: 0.8562\n",
      "Attribute attr_8: 0.8327\n",
      "Attribute attr_9: 0.8373\n",
      "Attribute attr_10: 0.8222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Prepare and process data\n",
    "women_tops_df = women_tops_df.drop(columns=['Category', 'len'])\n",
    "women_tops_df = women_tops_df.apply(\n",
    "    lambda col: col.fillna('dummy_value') if col.isna().all() \n",
    "    else col.fillna(col.mode()[0]) if col.dtype == 'object' or col.dtype.name == 'category' \n",
    "    else col\n",
    ")\n",
    "\n",
    "# Define attribute columns and category mappings\n",
    "attribute_columns_women_tops = [f'attr_{i}' for i in range(1, 11)]\n",
    "category_mappings_women_tops = {}\n",
    "\n",
    "for col in attribute_columns_women_tops:\n",
    "    women_tops_df[col] = pd.Categorical(women_tops_df[col])\n",
    "    category_mappings_women_tops[col] = dict(enumerate(women_tops_df[col].cat.categories))\n",
    "    women_tops_df[col] = women_tops_df[col].cat.codes\n",
    "\n",
    "women_tops_df['image_path'] = '/kaggle/input/visual-taxonomy/train_images/' + women_tops_df['id'].apply(lambda x: f\"{x:06d}.jpg\")\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_df_women_tops, temp_df = train_test_split(women_tops_df, test_size=0.3, random_state=42)\n",
    "val_df_women_tops, test_df_women_tops = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define number of classes for each attribute\n",
    "num_classes_per_attribute_women_tops = {\n",
    "    'attr_1': 12,\n",
    "    'attr_2': 4,\n",
    "    'attr_3': 2,\n",
    "    'attr_4': 7,\n",
    "    'attr_5': 2,\n",
    "    'attr_6': 3,\n",
    "    'attr_7': 6,\n",
    "    'attr_8': 4,\n",
    "    'attr_9': 4,\n",
    "    'attr_10': 6\n",
    "}\n",
    "\n",
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, num_classes_per_attribute):\n",
    "        super(MultiOutputModel, self).__init__()\n",
    "        \n",
    "        # Load ResNet101 as the base model\n",
    "        self.base_model = models.resnet101(pretrained=True)\n",
    "        \n",
    "        # Save the original fc's in_features before replacing it\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        \n",
    "        # Replace the fully connected layer with an identity layer\n",
    "        self.base_model.fc = nn.Identity()\n",
    "        \n",
    "        # Add dropout\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Create classification heads for each attribute\n",
    "        self.heads = nn.ModuleDict({\n",
    "            attr: nn.Linear(in_features, num_classes)\n",
    "            for attr, num_classes in num_classes_per_attribute.items()\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the base model\n",
    "        features = self.base_model(x)\n",
    "        \n",
    "        # Apply dropout\n",
    "        features = self.dropout(features)\n",
    "        \n",
    "        # Compute logits for each attribute\n",
    "        logits = {attr: head(features) for attr, head in self.heads.items()}\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Initialize the ResNet101-based model\n",
    "model_resnet101_women_tops = MultiOutputModel(num_classes_per_attribute_women_tops)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_str = str(self.df.iloc[idx][\"id\"]).zfill(6)\n",
    "        path = self.df.iloc[idx][\"image_path\"]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels = {attr: torch.tensor(self.df.iloc[idx][attr], dtype=torch.long) for attr in attribute_columns_women_tops}\n",
    "        return image, labels\n",
    "\n",
    "# Initialize datasets and data loaders\n",
    "train_dataset_women_tops = CustomDataset(train_df_women_tops, transform=data_augmentation)\n",
    "val_dataset_women_tops = CustomDataset(val_df_women_tops, transform=T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "test_dataset_women_tops = CustomDataset(test_df_women_tops, transform=T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "train_loader_women_tops = DataLoader(train_dataset_women_tops, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader_women_tops = DataLoader(val_dataset_women_tops, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader_women_tops = DataLoader(test_dataset_women_tops, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet101_women_tops.to(device)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler\n",
    "optimizer = torch.optim.AdamW(model_resnet101_women_tops.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training and Validation Loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model_resnet101_women_tops.train()\n",
    "    for images, labels in tqdm(train_loader_women_tops, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model_resnet101_women_tops(images)\n",
    "            losses = {attr: nn.CrossEntropyLoss()(outputs[attr], labels[attr].to(device)) for attr in labels}\n",
    "            total_loss = sum(losses.values())\n",
    "\n",
    "        scaler.scale(total_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model_resnet101_women_tops.eval()\n",
    "    val_corrects = {attr: 0 for attr in attribute_columns_women_tops}\n",
    "    val_samples = {attr: 0 for attr in attribute_columns_women_tops}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader_women_tops, desc=\"Validating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            outputs = model_resnet101_women_tops(images)\n",
    "            for attr in labels:\n",
    "                target = labels[attr].to(device)\n",
    "                _, preds = torch.max(outputs[attr], 1)\n",
    "                val_corrects[attr] += torch.sum(preds == target).item()\n",
    "                val_samples[attr] += target.size(0)\n",
    "\n",
    "    # Validation Accuracy per Attribute\n",
    "    for attr in attribute_columns_women_tops:\n",
    "        acc = val_corrects[attr] / val_samples[attr] if val_samples[attr] > 0 else 0\n",
    "        print(f\"Epoch {epoch + 1}, Validation Accuracy for {attr}: {acc:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model_resnet101_women_tops.eval()\n",
    "test_corrects = {attr: 0 for attr in num_classes_per_attribute_women_tops.keys()}\n",
    "test_samples = {attr: 0 for attr in num_classes_per_attribute_women_tops.keys()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader_women_tops, desc=\"Testing\", leave=False):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        outputs = model_resnet101_women_tops(images)\n",
    "        \n",
    "        for attr, target in labels.items():\n",
    "            # Move target to the device\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Get predicted class labels\n",
    "            _, preds = torch.max(outputs[attr], 1)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            test_corrects[attr] += torch.sum(preds == target).item()\n",
    "            test_samples[attr] += target.size(0)\n",
    "\n",
    "# Print test accuracy for each attribute\n",
    "print(\"\\nTest Accuracy per Attribute:\")\n",
    "for attr in num_classes_per_attribute_women_tops.keys():\n",
    "    test_acc = test_corrects[attr] / test_samples[attr] if test_samples[attr] > 0 else 0\n",
    "    print(f\"Attribute {attr}: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T10:29:49.752006Z",
     "iopub.status.busy": "2024-11-16T10:29:49.751584Z",
     "iopub.status.idle": "2024-11-16T10:50:16.497331Z",
     "shell.execute_reply": "2024-11-16T10:50:16.496233Z",
     "shell.execute_reply.started": "2024-11-16T10:29:49.751964Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_30/1847188934.py:141: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Training Epoch 1/10:   0%|          | 0/411 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_30/1847188934.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training Epoch 1/10: 100%|██████████| 411/411 [01:49<00:00,  4.12it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy for attr_1: 0.7536\n",
      "Epoch 1, Validation Accuracy for attr_2: 0.8999\n",
      "Epoch 1, Validation Accuracy for attr_3: 0.7784\n",
      "Epoch 1, Validation Accuracy for attr_4: 0.9499\n",
      "Epoch 1, Validation Accuracy for attr_5: 0.6772\n",
      "Epoch 1, Validation Accuracy for attr_6: 0.9386\n",
      "Epoch 1, Validation Accuracy for attr_7: 0.9652\n",
      "Epoch 1, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 1, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 1, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy for attr_1: 0.7599\n",
      "Epoch 2, Validation Accuracy for attr_2: 0.9041\n",
      "Epoch 2, Validation Accuracy for attr_3: 0.7947\n",
      "Epoch 2, Validation Accuracy for attr_4: 0.9606\n",
      "Epoch 2, Validation Accuracy for attr_5: 0.7088\n",
      "Epoch 2, Validation Accuracy for attr_6: 0.9450\n",
      "Epoch 2, Validation Accuracy for attr_7: 0.9616\n",
      "Epoch 2, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 2, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 2, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy for attr_1: 0.7731\n",
      "Epoch 3, Validation Accuracy for attr_2: 0.9084\n",
      "Epoch 3, Validation Accuracy for attr_3: 0.8097\n",
      "Epoch 3, Validation Accuracy for attr_4: 0.9574\n",
      "Epoch 3, Validation Accuracy for attr_5: 0.7109\n",
      "Epoch 3, Validation Accuracy for attr_6: 0.9478\n",
      "Epoch 3, Validation Accuracy for attr_7: 0.9670\n",
      "Epoch 3, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 3, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 3, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy for attr_1: 0.7926\n",
      "Epoch 4, Validation Accuracy for attr_2: 0.9073\n",
      "Epoch 4, Validation Accuracy for attr_3: 0.8065\n",
      "Epoch 4, Validation Accuracy for attr_4: 0.9620\n",
      "Epoch 4, Validation Accuracy for attr_5: 0.7266\n",
      "Epoch 4, Validation Accuracy for attr_6: 0.9467\n",
      "Epoch 4, Validation Accuracy for attr_7: 0.9698\n",
      "Epoch 4, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 4, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 4, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy for attr_1: 0.7848\n",
      "Epoch 5, Validation Accuracy for attr_2: 0.9048\n",
      "Epoch 5, Validation Accuracy for attr_3: 0.8093\n",
      "Epoch 5, Validation Accuracy for attr_4: 0.9620\n",
      "Epoch 5, Validation Accuracy for attr_5: 0.7205\n",
      "Epoch 5, Validation Accuracy for attr_6: 0.9489\n",
      "Epoch 5, Validation Accuracy for attr_7: 0.9698\n",
      "Epoch 5, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 5, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 5, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy for attr_1: 0.7873\n",
      "Epoch 6, Validation Accuracy for attr_2: 0.9077\n",
      "Epoch 6, Validation Accuracy for attr_3: 0.7994\n",
      "Epoch 6, Validation Accuracy for attr_4: 0.9641\n",
      "Epoch 6, Validation Accuracy for attr_5: 0.7219\n",
      "Epoch 6, Validation Accuracy for attr_6: 0.9460\n",
      "Epoch 6, Validation Accuracy for attr_7: 0.9673\n",
      "Epoch 6, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 6, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 6, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy for attr_1: 0.7972\n",
      "Epoch 7, Validation Accuracy for attr_2: 0.9112\n",
      "Epoch 7, Validation Accuracy for attr_3: 0.8196\n",
      "Epoch 7, Validation Accuracy for attr_4: 0.9656\n",
      "Epoch 7, Validation Accuracy for attr_5: 0.7259\n",
      "Epoch 7, Validation Accuracy for attr_6: 0.9499\n",
      "Epoch 7, Validation Accuracy for attr_7: 0.9659\n",
      "Epoch 7, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 7, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 7, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy for attr_1: 0.7905\n",
      "Epoch 8, Validation Accuracy for attr_2: 0.9091\n",
      "Epoch 8, Validation Accuracy for attr_3: 0.8232\n",
      "Epoch 8, Validation Accuracy for attr_4: 0.9638\n",
      "Epoch 8, Validation Accuracy for attr_5: 0.7283\n",
      "Epoch 8, Validation Accuracy for attr_6: 0.9478\n",
      "Epoch 8, Validation Accuracy for attr_7: 0.9670\n",
      "Epoch 8, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 8, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 8, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy for attr_1: 0.7987\n",
      "Epoch 9, Validation Accuracy for attr_2: 0.9105\n",
      "Epoch 9, Validation Accuracy for attr_3: 0.8246\n",
      "Epoch 9, Validation Accuracy for attr_4: 0.9648\n",
      "Epoch 9, Validation Accuracy for attr_5: 0.7308\n",
      "Epoch 9, Validation Accuracy for attr_6: 0.9482\n",
      "Epoch 9, Validation Accuracy for attr_7: 0.9684\n",
      "Epoch 9, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 9, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 9, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy for attr_1: 0.8047\n",
      "Epoch 10, Validation Accuracy for attr_2: 0.9094\n",
      "Epoch 10, Validation Accuracy for attr_3: 0.8249\n",
      "Epoch 10, Validation Accuracy for attr_4: 0.9659\n",
      "Epoch 10, Validation Accuracy for attr_5: 0.7319\n",
      "Epoch 10, Validation Accuracy for attr_6: 0.9489\n",
      "Epoch 10, Validation Accuracy for attr_7: 0.9698\n",
      "Epoch 10, Validation Accuracy for attr_8: 0.9986\n",
      "Epoch 10, Validation Accuracy for attr_9: 1.0000\n",
      "Epoch 10, Validation Accuracy for attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy per Attribute:\n",
      "Attribute attr_1: 0.7941\n",
      "Attribute attr_2: 0.9049\n",
      "Attribute attr_3: 0.8332\n",
      "Attribute attr_4: 0.9684\n",
      "Attribute attr_5: 0.7341\n",
      "Attribute attr_6: 0.9489\n",
      "Attribute attr_7: 0.9727\n",
      "Attribute attr_8: 0.9996\n",
      "Attribute attr_9: 1.0000\n",
      "Attribute attr_10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Prepare and process data\n",
    "women_tshirts_df = women_tshirts_df.drop(columns=['Category', 'len'])\n",
    "women_tshirts_df = women_tshirts_df.apply(\n",
    "    lambda col: col.fillna('dummy_value') if col.isna().all() \n",
    "    else col.fillna(col.mode()[0]) if col.dtype == 'object' or col.dtype.name == 'category' \n",
    "    else col\n",
    ")\n",
    "\n",
    "# Define attribute columns and category mappings\n",
    "attribute_columns_women_tshirts = [f'attr_{i}' for i in range(1, 11)]\n",
    "category_mappings_women_tshirts = {}\n",
    "\n",
    "for col in attribute_columns_women_tshirts:\n",
    "    women_tshirts_df[col] = pd.Categorical(women_tshirts_df[col])\n",
    "    category_mappings_women_tshirts[col] = dict(enumerate(women_tshirts_df[col].cat.categories))\n",
    "    women_tshirts_df[col] = women_tshirts_df[col].cat.codes\n",
    "\n",
    "women_tshirts_df['image_path'] = '/kaggle/input/visual-taxonomy/train_images/' + women_tshirts_df['id'].apply(lambda x: f\"{x:06d}.jpg\")\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_df_women_tshirts, temp_df = train_test_split(women_tshirts_df, test_size=0.3, random_state=42)\n",
    "val_df_women_tshirts, test_df_women_tshirts = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define number of classes for each attribute\n",
    "num_classes_per_attribute_women_tshirts = {\n",
    "    'attr_1': 7,\n",
    "    'attr_2': 3,\n",
    "    'attr_3': 3,\n",
    "    'attr_4': 3,\n",
    "    'attr_5': 6,\n",
    "    'attr_6': 3,\n",
    "    'attr_7': 2,\n",
    "    'attr_8': 2,\n",
    "    'attr_9': 1,\n",
    "    'attr_10': 1\n",
    "}\n",
    "\n",
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, num_classes_per_attribute):\n",
    "        super(MultiOutputModel, self).__init__()\n",
    "        \n",
    "        # Load ResNet101 as the base model\n",
    "        self.base_model = models.resnet101(pretrained=True)\n",
    "        \n",
    "        # Save the original fc's in_features before replacing it\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        \n",
    "        # Replace the fully connected layer with an identity layer\n",
    "        self.base_model.fc = nn.Identity()\n",
    "        \n",
    "        # Add dropout\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Create classification heads for each attribute\n",
    "        self.heads = nn.ModuleDict({\n",
    "            attr: nn.Linear(in_features, num_classes)\n",
    "            for attr, num_classes in num_classes_per_attribute.items()\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the base model\n",
    "        features = self.base_model(x)\n",
    "        \n",
    "        # Apply dropout\n",
    "        features = self.dropout(features)\n",
    "        \n",
    "        # Compute logits for each attribute\n",
    "        logits = {attr: head(features) for attr, head in self.heads.items()}\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Initialize the ResNet101-based model\n",
    "model_resnet101_women_tshirts = MultiOutputModel(num_classes_per_attribute_women_tshirts)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_str = str(self.df.iloc[idx][\"id\"]).zfill(6)\n",
    "        path = self.df.iloc[idx][\"image_path\"]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels = {attr: torch.tensor(self.df.iloc[idx][attr], dtype=torch.long) for attr in attribute_columns_women_tshirts}\n",
    "        return image, labels\n",
    "\n",
    "# Initialize datasets and data loaders\n",
    "train_dataset_women_tshirts = CustomDataset(train_df_women_tshirts, transform=data_augmentation)\n",
    "val_dataset_women_tshirts = CustomDataset(val_df_women_tshirts, transform=T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "test_dataset_women_tshirts = CustomDataset(test_df_women_tshirts, transform=T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "train_loader_women_tshirts = DataLoader(train_dataset_women_tshirts, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader_women_tshirts = DataLoader(val_dataset_women_tshirts, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader_women_tshirts = DataLoader(test_dataset_women_tshirts, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet101_women_tshirts.to(device)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler\n",
    "optimizer = torch.optim.AdamW(model_resnet101_women_tshirts.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training and Validation Loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model_resnet101_women_tshirts.train()\n",
    "    for images, labels in tqdm(train_loader_women_tshirts, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model_resnet101_women_tshirts(images)\n",
    "            losses = {attr: nn.CrossEntropyLoss()(outputs[attr], labels[attr].to(device)) for attr in labels}\n",
    "            total_loss = sum(losses.values())\n",
    "\n",
    "        scaler.scale(total_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model_resnet101_women_tshirts.eval()\n",
    "    val_corrects = {attr: 0 for attr in attribute_columns_women_tshirts}\n",
    "    val_samples = {attr: 0 for attr in attribute_columns_women_tshirts}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader_women_tshirts, desc=\"Validating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            outputs = model_resnet101_women_tshirts(images)\n",
    "            for attr in labels:\n",
    "                target = labels[attr].to(device)\n",
    "                _, preds = torch.max(outputs[attr], 1)\n",
    "                val_corrects[attr] += torch.sum(preds == target).item()\n",
    "                val_samples[attr] += target.size(0)\n",
    "\n",
    "    # Validation Accuracy per Attribute\n",
    "    for attr in attribute_columns_women_tshirts:\n",
    "        acc = val_corrects[attr] / val_samples[attr] if val_samples[attr] > 0 else 0\n",
    "        print(f\"Epoch {epoch + 1}, Validation Accuracy for {attr}: {acc:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model_resnet101_women_tshirts.eval()\n",
    "test_corrects = {attr: 0 for attr in num_classes_per_attribute_women_tshirts.keys()}\n",
    "test_samples = {attr: 0 for attr in num_classes_per_attribute_women_tshirts.keys()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader_women_tshirts, desc=\"Testing\", leave=False):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        outputs = model_resnet101_women_tshirts(images)\n",
    "        \n",
    "        for attr, target in labels.items():\n",
    "            # Move target to the device\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Get predicted class labels\n",
    "            _, preds = torch.max(outputs[attr], 1)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            test_corrects[attr] += torch.sum(preds == target).item()\n",
    "            test_samples[attr] += target.size(0)\n",
    "\n",
    "# Print test accuracy for each attribute\n",
    "print(\"\\nTest Accuracy per Attribute:\")\n",
    "for attr in num_classes_per_attribute_women_tshirts.keys():\n",
    "    test_acc = test_corrects[attr] / test_samples[attr] if test_samples[attr] > 0 else 0\n",
    "    print(f\"Attribute {attr}: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:16:46.889132Z",
     "iopub.status.busy": "2024-11-16T11:16:46.888758Z",
     "iopub.status.idle": "2024-11-16T11:16:46.925562Z",
     "shell.execute_reply": "2024-11-16T11:16:46.924659Z",
     "shell.execute_reply.started": "2024-11-16T11:16:46.889094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the image:\n",
      "attr_1: default\n",
      "attr_2: polo\n",
      "attr_3: solid\n",
      "attr_4: solid\n",
      "attr_5: short sleeves\n",
      "attr_6: dummy_value\n",
      "attr_7: dummy_value\n",
      "attr_8: dummy_value\n",
      "attr_9: dummy_value\n",
      "attr_10: dummy_value\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "def predict(image_path, model, category_mappings):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "    \n",
    "    # Make the prediction\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "\n",
    "    # Convert the predictions (logits) to class labels\n",
    "    predicted_labels = {}\n",
    "    for attr, output in outputs.items():\n",
    "        _, preds = torch.max(output, 1)  # Get the predicted class label\n",
    "        predicted_labels[attr] = category_mappings[attr][preds.item()]  # Map to corresponding value\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "# Example usage: Predict for a sample image\n",
    "image_path = \"/kaggle/input/visual-taxonomy/test_images/000000.jpg\"\n",
    "predictions = predict_image(image_path, model_resnet101, category_mappings_men_tshirts)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions for the image:\")\n",
    "for attr, label in predictions.items():\n",
    "    print(f\"{attr}: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:14:21.034273Z",
     "iopub.status.busy": "2024-11-16T11:14:21.033848Z",
     "iopub.status.idle": "2024-11-16T11:14:22.420056Z",
     "shell.execute_reply": "2024-11-16T11:14:22.419247Z",
     "shell.execute_reply.started": "2024-11-16T11:14:21.034222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model_resnet101.state_dict(), 'model_vit_men_tshirts_resnet101_new.pth')\n",
    "torch.save(model_resnet101_women_tops.state_dict(), 'model_vit_women_tops_resnet101_new.pth')\n",
    "torch.save(model_resnet101_women_tshirts.state_dict(), 'model_vit_women_tshirts_resnet101_new.pth')\n",
    "torch.save(model_kurtis.state_dict(), 'model_vit_kurtis_resnet101_new.pth')\n",
    "torch.save(model_resnet101_sarees.state_dict(), 'model_vit_sarees_resnet101_new.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:19:45.404048Z",
     "iopub.status.busy": "2024-11-16T11:19:45.403220Z",
     "iopub.status.idle": "2024-11-16T11:36:28.841724Z",
     "shell.execute_reply": "2024-11-16T11:36:28.840742Z",
     "shell.execute_reply.started": "2024-11-16T11:19:45.403990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 30205/30205 [16:43<00:00, 30.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CSV generated and saved as 'final_predictions_resnet101_new.csv'.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import contextlib\n",
    "from IPython.display import HTML\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Mapping of categories to their respective 'lens' values\n",
    "categories_number = {\n",
    "    'Men Tshirts': 5, \n",
    "    'Sarees': 10, \n",
    "    'Kurtis': 9, \n",
    "    'Women Tshirts': 8, \n",
    "    'Women Tops & Tunics': 10\n",
    "}\n",
    "\n",
    "model_selection = {\n",
    "    'Men Tshirts': model_resnet101,\n",
    "    'Sarees': model_resnet101_sarees,\n",
    "    'Kurtis': model_kurtis,\n",
    "    'Women Tshirts': model_resnet101_women_tshirts,\n",
    "    'Women Tops & Tunics': model_resnet101_women_tops\n",
    "}\n",
    "\n",
    "mapping_selection = {\n",
    "    'Men Tshirts': category_mappings_men_tshirts,\n",
    "    'Sarees': category_mappings_sarees,\n",
    "    'Kurtis': category_mappings_kurtis,\n",
    "    'Women Tshirts': category_mappings_women_tshirts,\n",
    "    'Women Tops & Tunics': category_mappings_women_tops\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the final results\n",
    "final_results = []\n",
    "\n",
    "# Iterate over the test DataFrame with tqdm for a single progress bar\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing Images\"):\n",
    "    category = row['Category']\n",
    "    \n",
    "    # Suppress output by redirecting stdout temporarily\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        image_path = '/kaggle/input/visual-taxonomy/test_images/' + \"{:06}\".format(row['id']) + '.jpg'\n",
    "        predictions = predict(image_path, model_selection[category], mapping_selection[category])\n",
    "    \n",
    "    # Extract attributes from the predictions\n",
    "    result = {\n",
    "        'id': row['id'],\n",
    "        'Category': category,\n",
    "        'len': categories_number[category],  # Set 'len' according to the category\n",
    "        **predictions  # Unpack the dictionary of attributes into the result\n",
    "    }\n",
    "    \n",
    "    final_results.append(result)\n",
    "\n",
    "# Create the final DataFrame from the results\n",
    "final_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('final_predictions_resnet101_new.csv', index=False)\n",
    "\n",
    "print(\"Final CSV generated and saved as 'final_predictions_resnet101_new.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to generate the train dataset predictions to be used for the final stacked ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:39:11.470374Z",
     "iopub.status.busy": "2024-11-16T11:39:11.469850Z",
     "iopub.status.idle": "2024-11-16T12:09:32.464056Z",
     "shell.execute_reply": "2024-11-16T12:09:32.463096Z",
     "shell.execute_reply.started": "2024-11-16T11:39:11.470306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 70213/70213 [30:20<00:00, 38.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CSV generated and saved as 'final_predictions_resnet101_new_train.csv'.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import contextlib\n",
    "from IPython.display import HTML\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Mapping of categories to their respective 'lens' values\n",
    "categories_number = {\n",
    "    'Men Tshirts': 5, \n",
    "    'Sarees': 10, \n",
    "    'Kurtis': 9, \n",
    "    'Women Tshirts': 8, \n",
    "    'Women Tops & Tunics': 10\n",
    "}\n",
    "\n",
    "model_selection = {\n",
    "    'Men Tshirts': model_resnet101,\n",
    "    'Sarees': model_resnet101_sarees,\n",
    "    'Kurtis': model_kurtis,\n",
    "    'Women Tshirts': model_resnet101_women_tshirts,\n",
    "    'Women Tops & Tunics': model_resnet101_women_tops\n",
    "}\n",
    "\n",
    "mapping_selection = {\n",
    "    'Men Tshirts': category_mappings_men_tshirts,\n",
    "    'Sarees': category_mappings_sarees,\n",
    "    'Kurtis': category_mappings_kurtis,\n",
    "    'Women Tshirts': category_mappings_women_tshirts,\n",
    "    'Women Tops & Tunics': category_mappings_women_tops\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the final results\n",
    "final_results = []\n",
    "\n",
    "# Iterate over the train DataFrame with tqdm for a single progress bar\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Processing Images\"):\n",
    "    category = row['Category']\n",
    "    \n",
    "    # Suppress output by redirecting stdout temporarily\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        image_path = '/kaggle/input/visual-taxonomy/train_images/' + \"{:06}\".format(row['id']) + '.jpg'\n",
    "        predictions = predict(image_path, model_selection[category], mapping_selection[category])\n",
    "    \n",
    "    # Extract attributes from the predictions\n",
    "    result = {\n",
    "        'id': row['id'],\n",
    "        'Category': category,\n",
    "        'len': categories_number[category],  # Set 'len' according to the category\n",
    "        **predictions  # Unpack the dictionary of attributes into the result\n",
    "    }\n",
    "    \n",
    "    final_results.append(result)\n",
    "\n",
    "# Create the final DataFrame from the results\n",
    "final_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('final_predictions_resnet101_new_train.csv', index=False)\n",
    "\n",
    "print(\"Final CSV generated and saved as 'final_predictions_resnet101_new_train.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T06:20:39.336662Z",
     "iopub.status.busy": "2024-11-13T06:20:39.335657Z",
     "iopub.status.idle": "2024-11-13T06:20:39.356326Z",
     "shell.execute_reply": "2024-11-13T06:20:39.355161Z",
     "shell.execute_reply.started": "2024-11-13T06:20:39.336611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "category_mappings_men_tshirts = {'attr_1': {0: 'black', 1: 'default', 2: 'multicolor', 3: 'white'}, 'attr_2': {0: 'polo', 1: 'round'}, 'attr_3': {0: 'printed', 1: 'solid'}, 'attr_4': {0: 'default', 1: 'solid', 2: 'typography'}, 'attr_5': {0: 'long sleeves', 1: 'short sleeves'}, 'attr_6': {0: 'dummy_value'}, 'attr_7': {0: 'dummy_value'}, 'attr_8': {0: 'dummy_value'}, 'attr_9': {0: 'dummy_value'}, 'attr_10': {0: 'dummy_value'}}\n",
    "category_mappings_sarees = {'attr_1': {0: 'default', 1: 'same as border', 2: 'same as saree', 3: 'solid'}, 'attr_2': {0: 'default', 1: 'no border', 2: 'solid', 3: 'temple border', 4: 'woven design', 5: 'zari'}, 'attr_3': {0: 'big border', 1: 'no border', 2: 'small border'}, 'attr_4': {0: 'cream', 1: 'default', 2: 'green', 3: 'multicolor', 4: 'navy blue', 5: 'pink', 6: 'white', 7: 'yellow'}, 'attr_5': {0: 'daily', 1: 'party', 2: 'traditional', 3: 'wedding'}, 'attr_6': {0: 'default', 1: 'jacquard', 2: 'tassels and latkans'}, 'attr_7': {0: 'default', 1: 'same as saree', 2: 'woven design', 3: 'zari woven'}, 'attr_8': {0: 'default', 1: 'printed', 2: 'solid', 3: 'woven design', 4: 'zari woven'}, 'attr_9': {0: 'applique', 1: 'botanical', 2: 'checked', 3: 'default', 4: 'elephant', 5: 'ethnic motif', 6: 'floral', 7: 'peacock', 8: 'solid'}, 'attr_10': {0: 'no', 1: 'yes'}}\n",
    "category_mappings_kurtis = {'attr_1': {0: 'black', 1: 'blue', 2: 'green', 3: 'grey', 4: 'maroon', 5: 'multicolor', 6: 'navy blue', 7: 'orange', 8: 'pink', 9: 'purple', 10: 'red', 11: 'white', 12: 'yellow'}, 'attr_2': {0: 'a-line', 1: 'straight'}, 'attr_3': {0: 'calf length', 1: 'knee length'}, 'attr_4': {0: 'daily', 1: 'party'}, 'attr_5': {0: 'default', 1: 'net'}, 'attr_6': {0: 'default', 1: 'solid'}, 'attr_7': {0: 'default', 1: 'solid'}, 'attr_8': {0: 'short sleeves', 1: 'sleeveless', 2: 'three-quarter sleeves'}, 'attr_9': {0: 'regular', 1: 'sleeveless'}, 'attr_10': {0: 'dummy_value'}}\n",
    "category_mappings_women_tshirts = {'attr_1': {0: 'black', 1: 'default', 2: 'maroon', 3: 'multicolor', 4: 'pink', 5: 'white', 6: 'yellow'}, 'attr_2': {0: 'boxy', 1: 'loose', 2: 'regular'}, 'attr_3': {0: 'crop', 1: 'long', 2: 'regular'}, 'attr_4': {0: 'default', 1: 'printed', 2: 'solid'}, 'attr_5': {0: 'default', 1: 'funky print', 2: 'graphic', 3: 'quirky', 4: 'solid', 5: 'typography'}, 'attr_6': {0: 'default', 1: 'long sleeves', 2: 'short sleeves'}, 'attr_7': {0: 'cuffed sleeves', 1: 'regular sleeves'}, 'attr_8': {0: 'applique', 1: 'default'}, 'attr_9': {0: 'dummy_value'}, 'attr_10': {0: 'dummy_value'}}\n",
    "category_mappings_women_tops = {'attr_1': {0: 'black', 1: 'blue', 2: 'default', 3: 'green', 4: 'maroon', 5: 'multicolor', 6: 'navy blue', 7: 'peach', 8: 'pink', 9: 'red', 10: 'white', 11: 'yellow'}, 'attr_2': {0: 'boxy', 1: 'default', 2: 'fitted', 3: 'regular'}, 'attr_3': {0: 'crop', 1: 'regular'}, 'attr_4': {0: 'default', 1: 'high', 2: 'round neck', 3: 'square neck', 4: 'stylised', 5: 'sweetheart neck', 6: 'v-neck'}, 'attr_5': {0: 'casual', 1: 'party'}, 'attr_6': {0: 'default', 1: 'printed', 2: 'solid'}, 'attr_7': {0: 'default', 1: 'floral', 2: 'graphic', 3: 'quirky', 4: 'solid', 5: 'typography'}, 'attr_8': {0: 'long sleeves', 1: 'short sleeves', 2: 'sleeveless', 3: 'three-quarter sleeves'}, 'attr_9': {0: 'default', 1: 'puff sleeves', 2: 'regular sleeves', 3: 'sleeveless'}, 'attr_10': {0: 'applique', 1: 'default', 2: 'knitted', 3: 'ruffles', 4: 'tie-ups', 5: 'waist tie-ups'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:38:15.773901Z",
     "iopub.status.busy": "2024-11-16T11:38:15.772827Z",
     "iopub.status.idle": "2024-11-16T11:38:15.779197Z",
     "shell.execute_reply": "2024-11-16T11:38:15.778057Z",
     "shell.execute_reply.started": "2024-11-16T11:38:15.773848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attr_1': {0: 'black', 1: 'default', 2: 'multicolor', 3: 'white'}, 'attr_2': {0: 'polo', 1: 'round'}, 'attr_3': {0: 'printed', 1: 'solid'}, 'attr_4': {0: 'default', 1: 'solid', 2: 'typography'}, 'attr_5': {0: 'long sleeves', 1: 'short sleeves'}, 'attr_6': {0: 'dummy_value'}, 'attr_7': {0: 'dummy_value'}, 'attr_8': {0: 'dummy_value'}, 'attr_9': {0: 'dummy_value'}, 'attr_10': {0: 'dummy_value'}}\n"
     ]
    }
   ],
   "source": [
    "print(category_mappings_men_tshirts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:38:28.366341Z",
     "iopub.status.busy": "2024-11-16T11:38:28.365936Z",
     "iopub.status.idle": "2024-11-16T11:38:28.371559Z",
     "shell.execute_reply": "2024-11-16T11:38:28.370572Z",
     "shell.execute_reply.started": "2024-11-16T11:38:28.366282Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attr_1': {0: 'default', 1: 'same as border', 2: 'same as saree', 3: 'solid'}, 'attr_2': {0: 'default', 1: 'no border', 2: 'solid', 3: 'temple border', 4: 'woven design', 5: 'zari'}, 'attr_3': {0: 'big border', 1: 'no border', 2: 'small border'}, 'attr_4': {0: 'cream', 1: 'default', 2: 'green', 3: 'multicolor', 4: 'navy blue', 5: 'pink', 6: 'white', 7: 'yellow'}, 'attr_5': {0: 'daily', 1: 'party', 2: 'traditional', 3: 'wedding'}, 'attr_6': {0: 'default', 1: 'jacquard', 2: 'tassels and latkans'}, 'attr_7': {0: 'default', 1: 'same as saree', 2: 'woven design', 3: 'zari woven'}, 'attr_8': {0: 'default', 1: 'printed', 2: 'solid', 3: 'woven design', 4: 'zari woven'}, 'attr_9': {0: 'applique', 1: 'botanical', 2: 'checked', 3: 'default', 4: 'elephant', 5: 'ethnic motif', 6: 'floral', 7: 'peacock', 8: 'solid'}, 'attr_10': {0: 'no', 1: 'yes'}}\n"
     ]
    }
   ],
   "source": [
    "print(category_mappings_sarees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:38:35.959400Z",
     "iopub.status.busy": "2024-11-16T11:38:35.958543Z",
     "iopub.status.idle": "2024-11-16T11:38:35.964276Z",
     "shell.execute_reply": "2024-11-16T11:38:35.963211Z",
     "shell.execute_reply.started": "2024-11-16T11:38:35.959346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attr_1': {0: 'black', 1: 'blue', 2: 'green', 3: 'grey', 4: 'maroon', 5: 'multicolor', 6: 'navy blue', 7: 'orange', 8: 'pink', 9: 'purple', 10: 'red', 11: 'white', 12: 'yellow'}, 'attr_2': {0: 'a-line', 1: 'straight'}, 'attr_3': {0: 'calf length', 1: 'knee length'}, 'attr_4': {0: 'daily', 1: 'party'}, 'attr_5': {0: 'default', 1: 'net'}, 'attr_6': {0: 'default', 1: 'solid'}, 'attr_7': {0: 'default', 1: 'solid'}, 'attr_8': {0: 'short sleeves', 1: 'sleeveless', 2: 'three-quarter sleeves'}, 'attr_9': {0: 'regular', 1: 'sleeveless'}, 'attr_10': {0: 'dummy_value'}}\n"
     ]
    }
   ],
   "source": [
    "print(category_mappings_kurtis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:38:49.126017Z",
     "iopub.status.busy": "2024-11-16T11:38:49.125618Z",
     "iopub.status.idle": "2024-11-16T11:38:49.131006Z",
     "shell.execute_reply": "2024-11-16T11:38:49.130020Z",
     "shell.execute_reply.started": "2024-11-16T11:38:49.125981Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attr_1': {0: 'black', 1: 'default', 2: 'maroon', 3: 'multicolor', 4: 'pink', 5: 'white', 6: 'yellow'}, 'attr_2': {0: 'boxy', 1: 'loose', 2: 'regular'}, 'attr_3': {0: 'crop', 1: 'long', 2: 'regular'}, 'attr_4': {0: 'default', 1: 'printed', 2: 'solid'}, 'attr_5': {0: 'default', 1: 'funky print', 2: 'graphic', 3: 'quirky', 4: 'solid', 5: 'typography'}, 'attr_6': {0: 'default', 1: 'long sleeves', 2: 'short sleeves'}, 'attr_7': {0: 'cuffed sleeves', 1: 'regular sleeves'}, 'attr_8': {0: 'applique', 1: 'default'}, 'attr_9': {0: 'dummy_value'}, 'attr_10': {0: 'dummy_value'}}\n"
     ]
    }
   ],
   "source": [
    "print(category_mappings_women_tshirts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T11:38:57.350487Z",
     "iopub.status.busy": "2024-11-16T11:38:57.350044Z",
     "iopub.status.idle": "2024-11-16T11:38:57.355717Z",
     "shell.execute_reply": "2024-11-16T11:38:57.354743Z",
     "shell.execute_reply.started": "2024-11-16T11:38:57.350442Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attr_1': {0: 'black', 1: 'blue', 2: 'default', 3: 'green', 4: 'maroon', 5: 'multicolor', 6: 'navy blue', 7: 'peach', 8: 'pink', 9: 'red', 10: 'white', 11: 'yellow'}, 'attr_2': {0: 'boxy', 1: 'default', 2: 'fitted', 3: 'regular'}, 'attr_3': {0: 'crop', 1: 'regular'}, 'attr_4': {0: 'default', 1: 'high', 2: 'round neck', 3: 'square neck', 4: 'stylised', 5: 'sweetheart neck', 6: 'v-neck'}, 'attr_5': {0: 'casual', 1: 'party'}, 'attr_6': {0: 'default', 1: 'printed', 2: 'solid'}, 'attr_7': {0: 'default', 1: 'floral', 2: 'graphic', 3: 'quirky', 4: 'solid', 5: 'typography'}, 'attr_8': {0: 'long sleeves', 1: 'short sleeves', 2: 'sleeveless', 3: 'three-quarter sleeves'}, 'attr_9': {0: 'default', 1: 'puff sleeves', 2: 'regular sleeves', 3: 'sleeveless'}, 'attr_10': {0: 'applique', 1: 'default', 2: 'knitted', 3: 'ruffles', 4: 'tie-ups', 5: 'waist tie-ups'}}\n"
     ]
    }
   ],
   "source": [
    "print(category_mappings_women_tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9755748,
     "sourceId": 84705,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
